{
  
    
        "post0": {
            "title": "Title",
            "content": "qc = QuantumCircuit(3) qc.ccx(0,1,2) transpile(qc, basis_gates=[&#39;cx&#39;, &#39;u3&#39;], optimization_level=3).draw(output=&#39;mpl&#39;) . qc = QuantumCircuit(5) qc.mct([0,1,2], 3) transpile(qc, basis_gates=[&#39;cx&#39;, &#39;u3&#39;], optimization_level=3).draw(output=&#39;mpl&#39;) .",
            "url": "https://idnm.github.io/blog/blog/2021/12/07/Untitled1.html",
            "relUrl": "/2021/12/07/Untitled1.html",
            "date": " • Dec 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "from qiskit import Par . qc = QuantumCircuit(1) a1, a2, a3 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] b1, b2, b3 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;, &#39;b3&#39;]] c1, c2, c3 = [Parameter(c) for c in [&#39;c1&#39;, &#39;c2&#39;, &#39;c3&#39;]] qc.u3(c1, c2, c3, 0) # qc.u3(b1, b2, b3, 0) qc.draw(output=&#39;mpl&#39;) .",
            "url": "https://idnm.github.io/blog/blog/2021/12/07/Untitled.html",
            "relUrl": "/2021/12/07/Untitled.html",
            "date": " • Dec 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "qc = QuantumCircuit(3) qc.ccx(0,1,2) transpile(qc, basis_gates=[&#39;cx&#39;, &#39;u3&#39;], optimization_level=3).draw(output=&#39;mpl&#39;) . qc = QuantumCircuit(5) qc.mct([0,1,2], 3) transpile(qc, basis_gates=[&#39;cx&#39;, &#39;u3&#39;], optimization_level=3).draw(output=&#39;mpl&#39;) .",
            "url": "https://idnm.github.io/blog/blog/2021/10/07/Untitled1.html",
            "relUrl": "/2021/10/07/Untitled1.html",
            "date": " • Oct 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Machine learning compilation of quantum circuits -- experiments",
            "content": "Introduction . import jax.numpy as jnp import numpy as np from jax import random, value_and_grad, ops, jit, lax, vmap, grad, partial key = random.PRNGKey(42) # !pip install tensornetwork # !pip install optax # !pip install qiskit # !pip install pylatexenc import tensornetwork as tn tn.set_default_backend(&#39;jax&#39;) import optax from qiskit import QuantumCircuit, transpile from qiskit.quantum_info import Operator, Statevector from qiskit.circuit import Parameter from qiskit.transpiler.passes.synthesis import UnitarySynthesis from qiskit.transpiler import PassManager from qiskit.converters import circuit_to_gate from scipy.stats import unitary_group import matplotlib.pyplot as plt import re from pandas import DataFrame . . WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.) . Motivation . Ever since I read the paper by L.Madden and A.Simonetto (original preprint, my review) I knew I want to do this kind of experiments myself. At first I hoped that there is a well-established framework where I can easily build quantum circuits and then optimize them efficiently. However, I was not able to find a good fit for my problem (I later found quimb which might do what I want, but in the end I&#39;m glad I worked things out from scratch). In the end I went for numpy+JAX combination which while being quite low-level was not a big problem to get working. . Here I will give a walk thorough this implementation and show experiments with compilation of random unitaries. However, in my opinion truly interesting stuff is concerned with the compilation of special gates, say multi-controlled Toffolis on restricted connectivity. I intend to look at this kind problems in detail in a future blog post, also see this preprint for advances in that direction. . NOTE:While I was working on my own experiments another preprint appeared, by P.Rakyta and Z.Zimborás, which is very similar to the work of M&amp;S in terms of numerical results. Despite the striking similarities these works are independent. As a bonus R&amp;Z also provide a numerical package SQUANDER that allows to play with their framework for compilation of unitaries. You might wish to check that out if you are interested in doing some experiments yourself. . The problem . OK, so first a brief recap of what is the compilation problem. Given a quantum circuit we need to find an equivalent one, which satisfies certain requirements. A typical restrictions are to use only some specific two-qubits gates and to be compatible with limited connectivity. I gave a more detailed intro here. Here is a nearly-trivial example: a simple $CNOT$ gate . qc = QuantumCircuit(2) qc.cx(0, 1) qc.draw(output=&#39;mpl&#39;) . . can be decomposed in terms of the entangling $CZ$ gate and single-qubit gates $rx, ry, rz$ as follows . qc_compiled = transpile(qc, basis_gates=[&#39;cz&#39;, &#39;rx&#39;, &#39;ry&#39;, &#39;rz&#39;], optimization_level=3) qc_compiled.draw(output=&#39;mpl&#39;) . . Now, for generic $n$-qubit unitaries one needs exponentially many entangling gates for the compilation. More precisely, there is a theoretical lower bound $ #CNOTs ge frac14 left(4^n-3n-1 right)$ on the amount of $CNOT$s required for compilation of any $n-$qubit unitary outside a measure zero set. Crucially, this measure zero set might in fact be of principal interest to quantum computing as it includes many operators featuring in most algorithms (such as multi-controlled gates). In this post I will only adress compilation of random unitaries and discuss compilation of special cases in a future post. For later reference here is the function returning a theoretical lower bound . def TLB(n): return int((4**n-3*n-1)/4 + 1) for n in range(1, 7): print(&#39;TLB for {}-qubit unitary is {}&#39;.format(n, TLB(n))) . TLB for 1-qubit unitary is 1 TLB for 2-qubit unitary is 3 TLB for 3-qubit unitary is 14 TLB for 4-qubit unitary is 61 TLB for 5-qubit unitary is 253 TLB for 6-qubit unitary is 1020 . Now, there is an algorithm called quantum Shannon decomposition to decompose an arbitary $n$-qubit unitary into a sequence of $CNOT$s and single-qubit rotations which requires roughly twice as many $CNOT$s as the theoretical lower bound implies. . 3-qubit example . As papers M&amp;S and R&amp;Z show, one can do better and eliminate the 2x overhead, at least numerically. Namely, it seems that precisely at the theoretical lower bound the exact or nearly-exact compilation is possible. Here is a real-life example. Consider the following 3-qubit circuit with $TLB(3)=14$ $CNOT$ gates . . The claim is that with the appropriate choice of angles in rotation gates it can morhp into any 3-qubit unitary. To find the corresponding angles it is sufficient to run a numerical optimization minimizing the fidelity between this circuit&#39;s unitary and the target unitary. This is rather imressive, but calls for many questions. Why choose $CNOT$ gates? Why place them in that exact order? It appears to be an experical fact that precise location of entangling gates as well as their choice ($CNOT$, $CZ$, etc) makes little difference. Moreover, even restricted connectivity does not seem to force an overhead for compilation. I will back up these claims with numerical experiments. . Contents . The rest of this post is divided into two parts. In the first I write some numpy/JAX/qiskit code that allows to construct and efficiently optimize circuits of interest. I try to give some explanations of the underlying numerical framework, but please do not mistake me for a real expert on the topic. Still, the resulting performance seems to be good enough to reproduce results of the existing preprints. This part can safely be skipped if you are only interested in the results. . In the second part of the post I will do a number of experiments compiling random unitaries with varying numbers of qubits, different types of entangling gates, restricted connectivity and try to draw some general lessons from them. . NOTE:This blog post is also a fully-functional jupyter notebook. You can open it in colab or download it and perform more experiments yourself! . Numerical framework . Building blocks for quantum circuits . First let us define the basic 1- and 2-qubit gates in matrix form. For now you can safely ignore the use jnp arrays instead of np arrays. . # Controlled-NOT (or controlled-X gate) cx_mat = jnp.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]) # Controlled-Z gate cz_mat = jnp.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, -1]]) # Pauli matrices x_mat = jnp.array([[0, 1], [1, 0]]) y_mat = jnp.array([[0, -1j], [1j, 0]], dtype=jnp.complex64) z_mat = jnp.array([[1, 0], [0, -1]]) # Rotation gates def rx_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*x_mat*jnp.sin(a/2) def ry_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*y_mat*jnp.sin(a/2) def rz_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*z_mat*jnp.sin(a/2) . The circuits that we are going to train will be built out of two types of 2-qubit blocks. Here are the definitions: . class block(): def __init__(self, gate_name, angles): self.gate_name = gate_name self.angles = angles # Quantum circuit in `qiskit` corresponding to our block def circuit(self): qc = QuantumCircuit(2) if self.gate_name == &#39;cx&#39;: qc.cx(0, 1) elif self.gate_name == &#39;cz&#39;: qc.cz(0, 1) else: print(&quot;Gate &#39;{}&#39; not yet supported&#39;&quot;.format(self.gate_name)) angles = np.array(self.angles) # convert from JAX array to numpy array if applicable. qc.ry(angles[0], 0) qc.rx(angles[1], 0) qc.ry(angles[2], 1) qc.rx(angles[3], 1) return qc # JAX-compatible unitary corresponding to our block def unitary(self): if self.gate_name == &#39;cx&#39;: entangling_matrix = cx_mat elif self.gate_name == &#39;cz&#39;: entangling_matrix = cz_mat else: print(&quot;Gate &#39;{}&#39; not yet supported&#39;&quot;.format(self.gate_name)) x_rotations = jnp.kron(rx_mat(self.angles[1]), rx_mat(self.angles[3])) y_rotations = jnp.kron(ry_mat(self.angles[0]), ry_mat(self.angles[2])) return x_rotations @ y_rotations @ entangling_matrix . Here is how they look: cz block . a0, a1, a2, a3 = [Parameter(a) for a in [&#39;a0&#39;, &#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] block(&#39;cz&#39;, [a0, a1, a2, a3]).circuit().draw(output=&#39;mpl&#39;) . and cx block . block(&#39;cx&#39;, [a0, a1, a2, a3]).circuit().draw(output=&#39;mpl&#39;) . Our block class can return a qiskit circuit and the correponding unitary matrix. Of course we could have extracted the unitary from the circuit itself via qiskit API, but this would make the matrix representation incompatible with JAX which will be our workhorse for optimization. So at this point we needed a bit of wheel reivention. Let&#39;s check that our implementation is consistent with qiskit: . key, subkey = random.split(key) angles = random.uniform(key, shape=(4,), minval=0, maxval=2*jnp.pi) for gate in [&#39;cx&#39;, &#39;cz&#39;]: b = block(gate, angles) qc = b.circuit() qs_unitary = Operator(qc.reverse_bits()).data # Yes, we need to reverse bits in qiskit to match our conventions. our_unitary = b.unitary() print(&#39;qiskit unitary is the same as our unitary for block with gate {}: {}&#39;.format(gate, jnp.allclose(qs_unitary, our_unitary))) . qiskit unitary is the same as our unitary for block with gate cx: True qiskit unitary is the same as our unitary for block with gate cz: True . To match matrix representations of quantum circuits might be a headache as I discussed in another post, so this was a neseccary check to do. . Our two bulding blocks (cz and cx) only differ by the type of the two-qubit gate. The circuits that we are going to build seem to do equally well for any choice of two-qubit gate. I will mostly use cz gate because it is symmetric under the swap of qubits, but I will also occasinally bring up the cx gate to illustrate that it has the same performance. Angles $a_0$-$a_3$ are going to be optimized. . Optimization with JAX . What is JAX? Well, it&#39;s basically numpy on steroids. You can check out the official documentation or numerous nice overwievs on the web. For our purposes two key features of JAX are . Autograd | JIT or just-in-time compilation | We will use the following measure of discrepance between two unitaries $disc(U, V) = 1- frac1{N} operatorname{Tr} left( U^ dagger V right)$ where $U,V$ are $N times N$ matices. It is normalized so that $disc(U,U)=0$. Note that this measure is insensitive to global phases of each matrix as is natural in our context. . def disc(U, U_target): n = U_target.shape[0] return 1-jnp.abs((U.conj() * U_target).sum())/n . Here is the optimization routine that we are going to use. I will not give much explanations, but illustrate with an example. . @partial(jit, static_argnums=(0, 1, )) # &lt; Here is where the magic happens! Remove this line and everything will run 1000 times slower:) def unitary_update(loss_and_grad, opt, opt_state, angles): loss, grads = loss_and_grad(angles) updates, opt_state = opt.update(grads, opt_state) angles = optax.apply_updates(angles, updates) return angles, opt_state, loss def unitary_learn(U_func, U_target, n_angles, init_angles=None, key=random.PRNGKey(0), learning_rate = 0.01, num_iterations=5000, target_disc = 1e-10): if init_angles is None: key = random.PRNGKey(0) angles = random.uniform(key, shape=(n_angles,), minval=0, maxval=2*jnp.pi) else: angles = init_angles loss_func = lambda angles: disc(U_func(angles), U_target) loss_and_grad = value_and_grad(loss_func) opt = optax.adam(learning_rate) opt_state = opt.init(angles) def update(angles, opt_state): return unitary_update(loss_and_grad, opt, opt_state, angles) angles_history=[] loss_history=[] for _ in range(num_iterations): angles, opt_state, loss = update(angles, opt_state) angles_history.append(angles) loss_history.append(loss) if loss &lt; target_disc: break return angles_history, loss_history . OK, now a very simple example. Say we want to find an $ZXZ$ decomposition of $Y$-gate. Define: . def zxz_ansatz(angles): return rz_mat(angles[0]) @ rx_mat(angles[1]) @ rz_mat(angles[2]) . Running the learning is now very simple: we give unitary_learn the function that is learning, the target unitary and also explicitly the number of parameters to be trained: . angles_history, loss_history = unitary_learn(zxz_ansatz, y_mat, 3) . We can visualize the pcoess of learning as follows: . plt.plot(loss_history) plt.yscale(&#39;log&#39;) . The learned angles in $ZXZ$ decomposition are . angles_history[-1] . DeviceArray([6.59216 , 3.1411407, 3.4505684], dtype=float32) . And it is not difficult to check directly that the result is equal to the $Y$ matrix up to a global phase. . Quantum circuits with numpy . We need to implement several procedures to construct unitaries of the quantum circuits. . def transposition(n, placement): w = len(placement) t = list(range(w, n)) for i, p in enumerate(placement): t.insert(p, i) return t def apply_gate_to_tensor(gate, tensor, placement): gate_width = int(len(gate.shape)/2) tensor_width = int(len(tensor.shape)/2) gate_contraction_axes = list(range(gate_width, 2*gate_width)) contraction = jnp.tensordot(gate, tensor, axes=[gate_contraction_axes, placement]) t = transposition(tensor_width, placement) + list(range(tensor_width, 2*tensor_width)) # last indices are intact return jnp.transpose(contraction, axes=t) def split_angles(angles, num_qubits, layer_len, num_layers, free_placements_len): surface_angles = angles[:3*num_qubits].reshape(num_qubits, 3) block_angles = angles[3*num_qubits:].reshape(-1, 4) layers_angles = block_angles[:layer_len*num_layers].reshape(num_layers, layer_len, 4) free_block_angles = block_angles[layer_len*num_layers:] return surface_angles, block_angles, layers_angles, free_block_angles def build_unitary(num_qubits, block_type, angles, layer_placements=[[], 0], free_placements=[]): layer, num_layers = layer_placements layer_depth = len(layer) num_blocks = len(layer)*num_layers+len(free_placements) surface_angles, _ , layers_angles, free_block_angles = split_angles(angles, num_qubits, len(layer), num_layers, len(free_placements)) # print(&#39;u angles are {}&#39;.format(angles)) # print(&#39;u surface angles are {}&#39;.format(surface_angles)) # print(&#39;u layers angles are {}&#39;.format(layers_angles)) # print(&#39;u free block angles are {}&#39;.format(free_blocks_angles)) u = jnp.identity(2**num_qubits).reshape([2]*num_qubits*2) # Initial round of single-qubit gates for i, a in enumerate(surface_angles): gate = rz_mat(a[2]) @ rx_mat(a[1]) @ rz_mat(a[0]) u = apply_gate_to_tensor(gate, u, [i]) # Sequence of layers wrapped in fori_loop. layers_angles = layers_angles.reshape(num_layers, layer_depth, 4) def apply_layer(i, u, layer, layers_angles): angles = layers_angles[i] for a, p in zip(angles, layer): gate = block(block_type, a).unitary().reshape(2,2,2,2) u = apply_gate_to_tensor(gate, u, p) return u if num_layers&gt;0: u = lax.fori_loop(0, num_layers, lambda i, u: apply_layer(i, u, layer, layers_angles), u) # Add remainder(free) blocks. for a, p in zip(free_block_angles, free_placements): gate = block(block_type, a).unitary().reshape(2,2,2,2) u = apply_gate_to_tensor(gate, u, p) return u.reshape(2**num_qubits, 2**num_qubits) . Packing everything together: ansatz circuits . Now, let us build our ansatz circuits from these blocks. . class ansatz(): def __init__(self, num_qubits, block_type, layer_placements=[[], 0], free_placements=[]): self.num_qubits = num_qubits self.block_type = block_type self.layer, self.num_layers = layer_placements self.free_placements = free_placements self.all_placements = self.layer*self.num_layers+free_placements self.num_angles = 3*num_qubits+4*len(self.all_placements) self.unitary = lambda angles: build_unitary(self.num_qubits, self.block_type, angles, [self.layer, self.num_layers], self.free_placements) def circuit(self, angles=None): if angles is None: angles = np.array([Parameter(&#39;a{}&#39;.format(i)) for i in range(self.num_angles)]) surface_angles, block_angles, _, _ = split_angles(angles, self.num_qubits, len(self.layer), self.num_layers, len(self.free_placements)) qc = QuantumCircuit(self.num_qubits) # Initial rounf of single-qubit gates for n, a in enumerate(surface_angles): qc.rz(a[0], n) qc.rx(a[1], n) qc.rz(a[2], n) # Entangling gates accoring to placements for a, p in zip(block_angles, self.all_placements): qc_block = block(self.block_type, a).circuit() qc = qc.compose(qc_block, p) return qc def learn(self, u_target, **kwargs): u_func = self.unitary return unitary_learn(u_func, u_target, self.num_angles, **kwargs) . ans = ansatz(3, &#39;cx&#39;, free_placements=[[0,1], [0,1]], layer_placements=[[[0,1], [1, 2], [0, 2]],3]) angles = random.uniform(key, shape=(ans.num_angles,), minval=0,maxval=2*jnp.pi) qs_u = Operator(ans.circuit(angles).reverse_bits()).data our_u = ans.unitary(angles) ans.circuit(angles).draw(output=&#39;mpl&#39;) print(jnp.allclose(qs_u, our_u)) # print(qs_u) # print(our_u) . True . Layers . def sequ_layer(num_qubits): return [[i,j] for i in range(num_qubits) for j in range(i+1, num_qubits)] def fill_layers(layer, depth): num_complete_layers = depth // len(layer) complete_layers = [layer, num_complete_layers] incomplete_layer = layer[:depth % len(layer)] return complete_layers, incomplete_layer . Experiments . Learning 2-qubit random unitary . Here is how we can learn a random two-qubit unitary. The ansatz is circuit is this: . u_target = unitary_group.rvs(4, random_state=0) ans = ansatz(2, &#39;cz&#39;, free_placements=[[0,1], [0,1], [0, 1]]) ans.circuit().draw(output=&#39;mpl&#39;) . Invoking the learning process is easy as pie: . %%time angles_history, loss_history = ans.learn(u_target) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 2.56 s, sys: 34.1 ms, total: 2.59 s Wall time: 2.54 s . The graph shows that we achive great fidelity in under 500 iterations. Just be be absolutely sure let us double-check using qiskit: . angles = angles_history[-1] qc = ans.circuit(angles) u_qs = Operator(qc.reverse_bits()).data disc(u_qs, u_target) . DeviceArray(2.3841858e-07, dtype=float32) . You can try various experiments here: changing gate type from cz to cx (shoud not affect the result), decreasing the number of layers (fidelity won&#39;t be nearly as good) etc. . Learning 3-qubit random unitary . OK, here instead of working at the theoretical lower bound let us make a sweep to see how fidelity increases (error drops) with the number of layers. . %%time n_q = 3 u_target = unitary_group.rvs(2**n_q, random_state=0) best_loss = [[], []] for depth in range(4): # TLB(3)=14 layer_placemets, free_placements = fill_layers(sequ_layer(n_q), depth) for i, gate in enumerate([&#39;cx&#39;, &#39;cz&#39;]): ans = ansatz(n_q, gate, layer_placements=layer_placemets, free_placements=free_placements) angles, loss_history = ans.learn(u_target, target_disc=10e-4) best_loss[i].append(min(loss_history)) plt.plot(best_loss[0], label=&#39;cx loss&#39;) plt.plot(best_loss[1], label=&#39;cz loss&#39;) plt.legend() . CPU times: user 43.5 s, sys: 1.75 s, total: 45.3 s Wall time: 40.1 s . The lesson here is that both types of two-qubits gate perform similarly well at all depths. I have not done experimenting with other gates, but I expect that this is very generic, i.e. it does not really matter what kind of gate to use at least as far as random unitaries are concerned. . Learning 6-qubit random unitary . I do know that 3 is followed by 4, but shall we perhaps get more ambitious? Let&#39;s try to compile a 6-qubit random unitary (you can change $n_q=6$ to whatever you like): . %%time n_q = 6 depth = TLB(n_q) layer_placements, free_placements = fill_layers(sequ_layer(n_q), depth) u_target = unitary_group.rvs(2**n_q, random_state=0) ans = ansatz(n_q, &#39;cz&#39;, layer_placements=layer_placements, free_placements=free_placements) angles_history, loss_history = ans.learn(u_target, num_iterations=10000) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 10min 39s, sys: 1min 24s, total: 12min 4s Wall time: 11min 54s . Note that depth of the theoretical lower bound for 6 qubits is $TLB(6)=1020$ which implies that there are $ approx 4000$ parameters in our ansatz. On my modest laptop the training completes in under 3 minutes. I would not claim this to be the cutting edge, but our JAX setup seems to be no worse than results from the published papers. . qc = QuantumCircuit(3) qc.ccx(0,1,2) u_toff3 = Operator(qc.reverse_bits()).data . %%time layer_placements, free_placements = fill_layers(sequ_layer(3), 7) ans = ansatz(3, &#39;cx&#39;, layer_placements=layer_placements, free_placements=free_placements) ans.circuit().draw(output=&#39;mpl&#39;) u = ans.unitary angles_history, loss_history = ans.learn(u_toff3) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 9.12 s, sys: 234 ms, total: 9.35 s Wall time: 8.58 s . Restricted topology .",
            "url": "https://idnm.github.io/blog/blog/qiskit/jax/machine%20learning/compilation/2021/09/30/Machine-learning-compilation-of-quantum-circuits-experiments.html",
            "relUrl": "/qiskit/jax/machine%20learning/compilation/2021/09/30/Machine-learning-compilation-of-quantum-circuits-experiments.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Title",
            "content": "from qiskit import Par . qc = QuantumCircuit(1) a1, a2, a3 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] b1, b2, b3 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;, &#39;b3&#39;]] c1, c2, c3 = [Parameter(c) for c in [&#39;c1&#39;, &#39;c2&#39;, &#39;c3&#39;]] qc.u3(c1, c2, c3, 0) # qc.u3(b1, b2, b3, 0) qc.draw(output=&#39;mpl&#39;) .",
            "url": "https://idnm.github.io/blog/blog/2021/09/24/Untitled.html",
            "relUrl": "/2021/09/24/Untitled.html",
            "date": " • Sep 24, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Matrix representation of quantum circuits - notations and gotchas",
            "content": "Intro . Usually, for experimenting with quantum circuits I use qiskit. As any higher level environment it is very convenient for common tasks, but may turn out too inflexible for unusual use cases. A somewhat opposite approach is to use much lower level tools to gain in flexibility at the expense of convenience. Currently I want to use Google&#39;s tensornetwork package for simulations and training of quantum circuits, but this requires building many things that are for free in qiskit from scratch. It is also necessary to become explicit about conventions for matrix representation of quantum circuits. As long as you stay within a single framework this may not be an issue. However for debugging purposes as well as for comparison between different frameworks this may become unavoidable. Thus, I always anticipated, that a day will come when I need to face my fears and order all terms in a tensor product by hands. Now it seems I&#39;m past the difficult part and I&#39;m better writing this down in case I would need to do something similar in the future. . Defining the problem . OK, so what is the problem? Consider the following simple circuit built with qiskit: . import numpy as np from qiskit import QuantumCircuit from qiskit.quantum_info import Operator, Statevector qc = QuantumCircuit(2) qc.x(0) qc.y(1) qc.cx(0,1) qc.draw(output=&#39;mpl&#39;) . . It is not hard or ambiguous to interpret what this circuit does by inspecting the diagram. Say the input state is $q_0=|0 rangle$, $q_1=|1 rangle$. After $X$ acts on $q_0$ it becomes $q_0 to X |0 rangle=|1 rangle$. Similarly, $q_1$ after $Y$ becomes $q_1 to Y|1 rangle=-i |0 rangle$. Since now $q_0$ is &quot;on&quot; the CNOT gate switches the state of $q_1$ further to $q_0 to -i|1 rangle$. So the end result is that $q_0=|0 rangle, q_1=|1 rangle$ is transformed to $q_0=|1 rangle, q_1=-i|1 rangle$. Or perhaps a picture says it better . . Similarly, we can work out what the circuit does for other computational basis states which by linearity fully fixes the action of the circuit. Although quite explicit, this is a clumsy description. This is why the matrix notation is usually used. And indeed, we can obtain the matrix corresponding to our quantum circuit quite easily in qiskit: . U_qs = Operator(qc).data U_qs . array([[0.+0.j, 0.+0.j, 0.+0.j, 0.-1.j], [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j, 0.-1.j, 0.+0.j]]) . It is important to realize that a number of conventions must be chosen before such explicit matrix representation can be written down. In particular, I will emphasize two points I tripped over while studying this: ordering of the qubit states in the tensor product or &quot;vertical ordering&quot; and ordering of operators or &quot;horizontal ordering&quot;. . . In the rest of the post I will clarify what are the conventions used in qiskit and how to reproduce the circuit with the tensornetwork library. . States: vertical ordering . Single qubit states . First we need to give matrix representations to two basis states of a single qubit. Here I think it is quite uncontroversial to choose begin{align} |0 rangle = begin{pmatrix}1 0 end{pmatrix}, qquad |1 rangle = begin{pmatrix}0 1 end{pmatrix} label{kets} end{align} . These are the &quot;ket&quot; vectors. Their &quot;bra&quot; counterparts are begin{align} langle 0| = begin{pmatrix}1 &amp; 0 end{pmatrix}, qquad langle 1| = begin{pmatrix}0 &amp; 1 end{pmatrix} label{bras} end{align} . With these, the following operators can be computed begin{align} |0 rangle langle 0| = begin{pmatrix}1 &amp; 0 0 &amp; 0 end{pmatrix}, qquad |0 rangle langle 1| = begin{pmatrix}0 &amp; 1 0 &amp; 0 end{pmatrix} nonumber |1 rangle langle 0| = begin{pmatrix}0 &amp; 0 1 &amp; 0 end{pmatrix}, qquad |1 rangle langle 1| = begin{pmatrix}0 &amp; 0 0 &amp; 1 end{pmatrix} label{ketbras} end{align} . Multiple qubit states . When there is more than a single qubit things become a bit more interesting and potentially confusing. For example, the combined Hilbert space of two qubits $ mathcal{H}_2$ is a tensor product of single-qubit Hilbert spaces $ mathcal{H}_2 = mathcal{H}_1 otimes mathcal{H}_1$ but we need to decide which qubit goes first and which goes second. In qiskit a convention is adopted that additional qubits join from the left, i.e. when we have two qubits as here . qc01 = QuantumCircuit(2) qc01.draw(output=&#39;mpl&#39;) . . The state of the system is $|q_1 rangle otimes |q_0 rangle$ (this is of course only true literally for non-entangled states but we can define everything only on the computational basis states ). OK, but how do we translate this into the matrix representation? The states in the tensor product of vector spaces can be represented by the Kronecker product which is not symmetric with respect to permutation arguments. Best way to explain how Kronecker product works is, as usual, through examples: . begin{align} begin{pmatrix} 1 0 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} a b 0 0 end{pmatrix}, qquad begin{pmatrix} 0 1 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} 0 0 a b end{pmatrix} end{align}Result for generic left vector can be obtained by linearity begin{align} begin{pmatrix} x y end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = x begin{pmatrix} 1 0 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} +y begin{pmatrix} 0 1 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} x a x b y a y b end{pmatrix} = begin{pmatrix} x begin{pmatrix} a b end{pmatrix} y begin{pmatrix} a b end{pmatrix} end{pmatrix} end{align} . The last notation here is a bit informal but it shows what happens. One just substitutes the right vector into all elements of the left vector, multiplied by the corresponding components of the left vector. The Kronecker product is defined in the same way for matrices of arbitrary size, not just for two vectors. . So, now we can compute matrix representations of states in the computation basis of two-qubit system . begin{align} |00 rangle = begin{pmatrix}1 0 end{pmatrix} otimes begin{pmatrix}1 0 end{pmatrix} = begin{pmatrix}1 0 0 0 end{pmatrix}, quad |01 rangle = begin{pmatrix}1 0 end{pmatrix} otimes begin{pmatrix}0 1 end{pmatrix} = begin{pmatrix}0 1 0 0 end{pmatrix} label{01} |10 rangle = begin{pmatrix}0 1 end{pmatrix} otimes begin{pmatrix}1 0 end{pmatrix} = begin{pmatrix}0 0 1 0 end{pmatrix}, quad |11 rangle = begin{pmatrix}0 1 end{pmatrix} otimes begin{pmatrix}0 1 end{pmatrix} = begin{pmatrix}0 0 0 1 end{pmatrix} end{align}There is a useful relation between the index of the non-zero element $n$ in the four-dimensional representation and the computational basis bitstring $q_1q_0$, namely $n=2q_1+q_0$. I.e. the bitstring $q_1q_0$ is the binary representation of the index $n$. This extends to arbitrary number of qubits, for example since $101$ is $5$ in binary representation it follows begin{align} |101 rangle = begin{pmatrix}0 0 0 0 0 1 0 0 end{pmatrix} label{101} end{align} (try to obtain this from the two tensor products!) . Don&#39;t believe me? OK, let&#39;s check! In qiskit there is a convenient function to construct a vector representation from a bit string which we will take advantage of. First start with a two-qubit example: . s01 = Statevector.from_label(&#39;01&#39;) s01.data . array([0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]) . Comparing to eqref{01} we find agreement. Similarly, . s101 = Statevector.from_label(&#39;101&#39;) s101.data . array([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]) . Again, this is in agreement with eqref{101}. . However, I am not sure that this relation is sufficient to justify the ordering of the tensor products. To me it is much more natural to read the circuit from top to bottom and construct the Hilbert spaces accordingly, say $ mathcal{H}_0 otimes mathcal{H}_1 otimes mathcal{H}_2 dots$ instead of $ cdots mathcal{H}_2 otimes mathcal{H}_1 otimes mathcal{H}_0$. Later I will change the ordering of the tensor product to my liking, but for now we stick with the qiskit one. Now, with conventions for states in place we can proceed to operators. . Operators: horizontal ordering . One can say that convention for states representation and ordering of tensor products is a &quot;vertical&quot; convention. There is also a &quot;horizontal&quot; convention which might be potentially confusing. Consider the following circuit . qc123 = QuantumCircuit(1) qc123.rx(1, 0) qc123.ry(2, 0) qc123.rz(3, 0) qc123.draw(output=&#39;mpl&#39;) . . Here, the operator $R_x$ is appplied first, the operator $R_y$ second and $R_z$ last. So in mathematical notation the circuit corresponds to $R_z R_y R_x$ and not to $R_x R_y R_z$. I think that the circuit notation is actually better. We think and write from left to right, this is also a direction that time flows on paper. When another thing happens, we write it to the right and it would be convenient to apply the corresponding operator also to the right. I heard real mathematicians complain about that issue, but I guess we are stuck with it for now. . Paper-and-pencil computation . With the set up in place we can compute the circuit of interest by hands. For convenience I plot it here once again: . qc.draw(output=&#39;mpl&#39;) . . OK, so what is the unitary matrix corresponding to this circuit? It is begin{align} U = CNOT_{01} cdot (Y otimes X) end{align} Here begin{multline} CNOT_{01} = mathbb{1} otimes |0 rangle langle 0|+X otimes |1 rangle langle 1|= begin{pmatrix}1&amp;0 0&amp;1 end{pmatrix} otimes begin{pmatrix}1&amp;0 0&amp;0 end{pmatrix}+ begin{pmatrix}0&amp;1 1&amp;0 end{pmatrix} otimes begin{pmatrix}0&amp;0 0&amp;1 end{pmatrix}= begin{pmatrix}1&amp;0&amp;0&amp;0 0&amp;0&amp;0&amp;1 0&amp;0&amp;1&amp;0 0&amp;1&amp;0&amp;0 end{pmatrix} end{multline} and begin{align} Y otimes X = begin{pmatrix} 0&amp; -i i&amp;0 end{pmatrix} otimes begin{pmatrix} 0&amp; 1 1&amp;0 end{pmatrix}= begin{pmatrix}0&amp;0&amp;0&amp;-i 0&amp;0&amp;-i&amp;0 0&amp;i&amp;0&amp;0 i&amp;0&amp;0&amp;0 end{pmatrix} end{align} Multiplying them together gives begin{align} U = begin{pmatrix}0 &amp; 0 &amp; 0 &amp; -i i&amp;0&amp;0&amp;0 0 &amp; i &amp; 0 &amp; 0 0 &amp; 0 &amp; -i &amp; 0 end{pmatrix} end{align} Alright, so this is indeed the matrix that qiskit computes: . U_qs . array([[0.+0.j, 0.+0.j, 0.+0.j, 0.-1.j], [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j, 0.-1.j, 0.+0.j]]) . We can now also check that that the states evolve as we expected. For example recall that we computed that our quantum circuit maps $q_0 =|0 rangle, q_1 =|1 rangle$ to $q_0 =|1 rangle, q_1 =|1 rangle$ with an overall phase $-i$. Agreement with qiskit can be checked as follows: . qs_state = Statevector.from_label(&#39;10&#39;).evolve(qc).data our_state = -1j*Statevector.from_label(&#39;11&#39;).data np.allclose(qs_state, our_state) . True . Implementation with tensornetworks . I will not give a proper introduction to tensor networks but just make some digressions I think should be helpful as we go along. . First thing we will need are the matrices defining $X, Y$ and $CNOT$ gates. Let us introduce them. . X = np.array([[0, 1], [1, 0]]) Y = np.array([[0, -1j], [1j, 0]]) CNOT = np.array([[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0]]).reshape(2,2,2,2) . An aside about reshaping . Note that as usually written, $CNOT$ is a $4 times4$ matrix. Since as a quantum gate it acts on two qubits, so it should rather be a four-legged tensor. This is the purpose of the reshaping operation. At first the reshaping might be a bit tricky, so let me illustrate it with an example. Introduce two $4 times4$ matrices and define their product: . A = np.random.rand(4,4) B = np.random.rand(4,4) AB = A @ B . Now define the corresponding four-legged tensors. . import tensornetwork as tn a = tn.Node(A.reshape(2,2,2,2)) b = tn.Node(B.reshape(2,2,2,2)) . By contracting the legs (or &quot;edges&quot; in terminology of tensornetworks) appropriately, we can reproduce the matrix multiplication. First the code: . a[2] ^ b[0] a[3] ^ b[1] ab = tn.contractors.greedy([a, b], output_edge_order=[a[0], a[1], b[2], b[3]]).tensor . We can check that the contraction performed in this way exactly reproduces the matrix multiplication of original $4 times4$ matrices: . np.allclose(AB, ab.reshape(4,4)) . True . This can be interpreted graphically as follows. First, the reshaping procedure can be thought of as splitting each of two four-dimensional legs of the original matrix into two two-dimensional ones . . The labels on the legs have nothing to do with qubit states, these are just indices of edges as assigned by tn.Node operation on our matrices. The matrix multiplication of the original matrices in terms of four-legged tensors then can be drawn as follows . . The index arrangements in the last part explain why we connected the edges in our code the way we did. This is something to watch out for. For example, connecting edges of two identity tensors in the wrong way may produce a $SWAP$ gate. . Tensor product ordering . The matrix representation of a tensor diagram like this . . also comes with a convention for the ordering of tensor products. In tensornetwork as well as in my opinion it is natural to order top-down, i.e. the above diagram is $U otimes mathbb{1}$ instead of $ mathbb{1} otimes U$ as is adopted in qiskit. . Circuit from tensor network . Alright, not we are in a position to reproduce the circuit unitary from the tensor network with nodes x, y and cnot: . # Make tensors from matrices x, y, cnot = list(map(tn.Node, [X, Y, CNOT])) # Connect edges properly cnot[2] ^ y[0] cnot[3] ^ x[0] # Perform the contraction ~ matrix multiplication U_tn = tn.contractors.greedy([cnot, x, y], output_edge_order=[cnot[0], cnot[1], y[1], x[1]]).tensor . This way of contracting the edges corresponds to the following diagram: . . Note that this is basically the original circuit with both the vertical and the horizontal directions reversed. The horizontal reversal is due to mathematical vs circuit notation (circuit is better!) and the vertical reversal is due to the mismatch between qiskit and tensornetwork ordering of tensor product (tensornetwork&#39;s is better!). We can check that the unitary we obtain from this tensor network agrees with qiskit&#39;s . np.allclose(U_tn.reshape(4,4), U_qs) . True . A better way . I find all this misalignment very inconvenient and hard to debug. Ideally I want to look at the quantum circuit and construct the corresponding tensor network just as I read a text: from left to right and from top to bottom. Here I propose a solution which seems much more satisfactory to me. We will deal with horizontal reversal by first defining edges and then applying gates to them. This way we can read the circuit from left to right and simply add new gates, just as in qiskit. I will not try to revert the vertical direction directly, because I find it hard to think upside down. Instead, for comparison with qiskit I will use a built-in reverse_bits method. . So let&#39;s start by defining a function that applies a given gate to the collection of qubits (this is a slight modification of an example from tensornetwork docs) : . def apply_gate(qubits, gate_tensor, positions): gate = tn.Node(gate_tensor) assert len(gate.edges) == 2*len(positions), &#39;Gate size does not match positions provided.&#39; for i, p in enumerate(positions): # Connect RIGHT legs of the gate to the active qubits gate[i+len(positions)] ^ qubits[p] # Reassing active qubits to the corresponding LEFT legs of the gate qubits[p] = gate[i] . Importantly, here, in contrast to the official docs, we append the gate from the left, so that a sequence of application of some $G_1$ followed by $G_2$ is equivalent to the application of $G_2 cdot G_1$. Now there is one more subtlety. Previously we used matrix representation of $CNOT$ assuming that the uppermost qubit comes last in the tensor product. Now that we decided to turn this convention upside down our matrix representation of $CNOT$ must be $CNOT =|0 rangle langle 0| otimes mathbb{1}+|1 rangle langle 1| otimes X$ or explicitly . CNOT = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]).reshape(2,2,2,2) . With that we are ready to reconstruct our original circuit in a convenient way: . # The context manager `NodeCollection` is a bit of a magic trick # which keeps track of all tensors in the network automatically. all_nodes = [] with tn.NodeCollection(all_nodes): # I do not know how to create &#39;abstract&#39; edges in `tensornetworks`. # Instead, I create an identity tensor and use its edges to apply new gates to. id0 = tn.Node(np.identity(4).reshape(2,2,2,2)) qubits0 = id0.edges[2:4] qubits = id0.edges[0:2] apply_gate(qubits, X, [0]) apply_gate(qubits, Y, [1]) apply_gate(qubits, CNOT, [0,1]) . Now let us check! . U_tn = tn.contractors.greedy(all_nodes, output_edge_order=qubits+qubits0).tensor.reshape(4,4) U_reversed_qs = Operator(qc.reverse_bits()).data np.allclose(U_tn, U_reversed_qs) . True . Wohoo, it worked! If that looked simple to you I&#39;m happy. It took me several hours of debugging to finally match the two matrices. Just to make sure, let me conclude with a more complicated example. . qc3 = QuantumCircuit(3) qc3.x(0) qc3.cx(0, 1) qc3.y(1) qc3.x(2) qc3.cx(2, 1) qc3.y(2) qc3.draw(output=&#39;mpl&#39;) . As you can see, constructing the tensor network analog now works more or less identically: . all_nodes = [] with tn.NodeCollection(all_nodes): id0 = tn.Node(np.identity(8).reshape(2,2,2,2,2,2)) qubits0 = id0.edges[3:6] qubits = id0.edges[0:3] # The essential part apply_gate(qubits, X, [0]) apply_gate(qubits, CNOT, [0, 1]) apply_gate(qubits, Y, [1]) apply_gate(qubits, X, [2]) apply_gate(qubits, CNOT, [2, 1]) apply_gate(qubits, Y, [2]) . And now we compare: . U3_tn = tn.contractors.greedy(all_nodes, output_edge_order=qubits+qubits0).tensor.reshape(8,8) U3_qs_reversed = Operator(qc3.reverse_bits()).data np.allclose(U3_tn, U3_qs_reversed) . True . Alright, this resounding True is the best way to conclude that comes to mind. I own many thanks to Ilia Luchnikov for the help with tensornetwork library. Any questions are welcome in the comments! .",
            "url": "https://idnm.github.io/blog/blog/qiskit/tensor%20networks/quantum%20concepts/2021/08/18/Matrix-representation-of-quantum-circuits.html",
            "relUrl": "/qiskit/tensor%20networks/quantum%20concepts/2021/08/18/Matrix-representation-of-quantum-circuits.html",
            "date": " • Aug 18, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Machine learning compilation of quantum circuits",
            "content": "Introduction . I am going to review a recent preprint by Liam Madden and Andrea Simonetto that uses techniques from machine learning to tackle the problem of quantum circuits compilation. I find the approach suggested in the paper very interesting and the preliminary results quite promising. . What is compilation? . Note that a variety of terms are floating around the literature and used more or less interchangibly. Among those are synthesis, compilation, transpilation and decomposition of quantum circuits. I will not make a distinction and try to stick to compilation. . But first things first, what is a compilation of a quantum circuit? The best motivation and illustration for the problem is the following. Say you need to run a textbook quantum circuit on a real hardware. The real hardware usually allows only for a few basic one and two qubit gates. In contrast, your typical textbook quantum circuit may feature (1) complex many-qubit gates, for example multi-controlled gates and (2) one and two qubit gates which are not supported by the hardware. As a simple example take this 3-qubit Grover&#39;s circuit (from qiskit textbook): . #initialization import matplotlib.pyplot as plt import numpy as np # importing Qiskit from qiskit import IBMQ, Aer, assemble, transpile from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister from qiskit.providers.ibmq import least_busy # import basic plot tools from qiskit.visualization import plot_histogram def initialize_s(qc, qubits): &quot;&quot;&quot;Apply a H-gate to &#39;qubits&#39; in qc&quot;&quot;&quot; for q in qubits: qc.h(q) return qc def diffuser(nqubits): qc = QuantumCircuit(nqubits) # Apply transformation |s&gt; -&gt; |00..0&gt; (H-gates) for qubit in range(nqubits): qc.h(qubit) # Apply transformation |00..0&gt; -&gt; |11..1&gt; (X-gates) for qubit in range(nqubits): qc.x(qubit) # Do multi-controlled-Z gate qc.h(nqubits-1) qc.mct(list(range(nqubits-1)), nqubits-1) # multi-controlled-toffoli qc.h(nqubits-1) # Apply transformation |11..1&gt; -&gt; |00..0&gt; for qubit in range(nqubits): qc.x(qubit) # Apply transformation |00..0&gt; -&gt; |s&gt; for qubit in range(nqubits): qc.h(qubit) # We will return the diffuser as a gate U_s = qc.to_gate() U_s.name = &quot;U$_s$&quot; return U_s qc = QuantumCircuit(3) qc.cz(0, 2) qc.cz(1, 2) oracle_ex3 = qc.to_gate() oracle_ex3.name = &quot;U$_ omega$&quot; n = 3 grover_circuit = QuantumCircuit(n) grover_circuit = initialize_s(grover_circuit, [0,1,2]) grover_circuit.append(oracle_ex3, [0,1,2]) grover_circuit.append(diffuser(n), [0,1,2]) grover_circuit = grover_circuit.decompose() grover_circuit.draw(output=&#39;mpl&#39;) . . The three qubit gates like Toffoli are not generally available on a hardware and one and two qubit gates my be different from those in the textbook algorithm. For example ion quantum computers are good with Mølmer–Sørensen gates and may need several native one qubit gates to implement the Hadamard gate. . Additional important problem is to take into account qubit connectivity. Usually textbook algorithms assume full connectivity, meaning that two-qubit gates can act on any pair of qubits. On most hardware platforms however a qubit can only interact with its neighbors. Assuming that one and two qubits gates available on the hardware can implement a SWAP gate between adjacent qubits, to solve the connectivity problem one can insert as many SWAPs as necessary to connect topologically disjoint qubits. Using SWAPs however leads to a huge overhead in the number of total gates in the compiled circuit, and it is of much importance use them as economically as possible. In fact, the problem of optimal SWAPping alone in generic situation is NP-complete. . Simplified problem . When compiling a quantum circuit one has to decide which resulting circuits are considered to be efficient. Ideally, one should optimize for the total fidelity of the circuit. Let us imagine running the algorithm on a real device. Probably my theorist&#39;s image of a real device is still way too platonic, but I will try my best. Many details need to be taken into account. For example, gates acting on different qubits or pairs of qubits may have different fidelities. Decoherence of qubits with time can make circuits where many operations can be executed in parallel more favorable. Cross-talk (unwanted interactions) between neighboring qubits may lead to exotic patterns for optimal circuits. A simple proxy for the resulting fidelity that is often adopted is the number of two-qubit gates (which are generically much less accurate than a single-qubit gates). So the problem that is often studied, and that is addressed in the preprint we are going to discuss, is the problem of optimal compilation into a gate set consisting of arbitrary single-qubit gates and CNOTs, the only two qubits gate. The compiled circuit must . Respect hardware connectivity. | Have as few CNOTs as possible. | Exceed a given fidelity threshold. | Last item here means that we also allow for an approximate compilation. By increasing the number of CNOTs one can always achieve an exact compilation, but since in reality each additional CNOT comes with its own fidelity cost this might not be a good trade-off. Note also that a specific choice for two-qubit gate is made, a CNOT gate. Any two-qubit gate can be decomposed into at most 3 CNOTs see e.g. here, so in terms of computational complexity this is of course inconsequential. However in the following discussion we will care a lot about constant factors and may wish to revisit this choice at the end. . Existing results . Since finding the exact optimal solution to the compilation problem is intractable, as with many things in life one needs to resort to heuristic methods. A combination of many heuristic methods, in fact. As an example one can check out the transpilation workflow in qiskit. Among others, there is a step that compiles &gt;2 qubit gates into one and two qubit gates; the one that tries to find a good initial placement of the logical qubits onto physical hardware; the one that &#39;routes&#39; the desired circuit to match a given topology being as greedy on SWAPs as possible. Each of these steps can use several different heuristic optimization algorithms, which are continuously refined and extended (for example this recent preprint improves on the default rounting procedure in qiskit). In my opinion it would be waay better to have one unified heuristic for all steps of the process, especially taking into account that they are not completely independent. Although this might be too much to ask for, some advances are definitely possible and machine learning tools might prove very useful. The paper we are going to discuss is an excellent demonstration. . Theoretical lower bound and quantum Shannon decomposition . There is a couple of very nice theoretical results about the compilation problem that I need to mention. But first, let us agree that we will compile unitaries, not circuits. What is the difference? Of course, any quantum circuit (without measurements and neglecting losses) corresponds to a unitary matrix. However, to compute that unitary matrix for a large quantum circuit explicitly is generally an intractable problem, precisely for the same reasons that quantum computation is assumed to be more powerful than classical. Still, taking as the input a unitary matrix (which is in general hard to compute from the circuit) is very useful both theoretically and practically. I will discuss pros and cons of this approach later on. . OK, now the fun fact. Generically, one needs at least this many CNOTs . begin{align} L:= # text{CNOTs} geq frac14 left(4^n-3n-1 right) label{TLB} end{align}to exactly compile an $n$-qubit unitary. &#39;Generically&#39; means that the set of $n$-qubit unitaries that can be compiled exactly with smaller amount of CNOTs has measure zero. Keep in mind though, that there are important unitaries in this class like multi-controlled gates or qubit permutations. We will discuss compilation of some gates from the &#39;measure-zero&#39; later on. . The authors of the preprint (I hope you and me still remember that there is some actual results to discuss, not just my overly long introduction to read) refer to eqref{TLB} as the theoretical lower bound or TLB for short. The proof of this fact is actually rather simple and I will sketch it. A general $d times d$ unitary has $d^2$ real parameters. For $n$ qubits $d=2^n$. Single one-qubit gate has 3 real parameters. Any sequence of one-qubit gates applied to the same qubit can be reduced to a single one-qubit gate and hence can have no more than 3 parameters. That means, that without CNOTs we can only have 3n parameters in our circuit, 3 for each one-qubit gate. This is definitely not enough to describe an arbitrary unitary on $n$ qubits which has $d^2=4^n$ parameters. . Now, adding a single CNOT allows to insert two more 1-qubit unitaries after it, like that . from qiskit.circuit import Parameter a1, a2, a3 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] b1, b2, b3 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;, &#39;b3&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.u(a1, a2, a3, 0) qc.u(b1, b2, b3, 1) qc.draw(output=&#39;mpl&#39;) . . At the first glance this allows to add 6 more parameters. However, each single-qubit unitary can be represented via the Euler angles as a product of only $R_z$ and $R_x$ rotations either as $U=R_z R_x R_z$ or $U=R_x R_y R_z$ (I do not specify angles). Now, CNOT can be represented as $CNOT=|0 rangle langle 0| otimes I+|1 rangle langle 1| otimes X$. It follows that $R_z$ commutes with the control of CNOT and $R_x$ commutes with the target of CNOT, hence they can be dragged to the left and joined with preceding one-qubit gates. So in fact each new CNOT gate allows to add only 4 real parameters: . a1, a2 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;]] b1, b2 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.rx(a1, 0) qc.rz(a2, 0) qc.rz(b1, 1) qc.rx(b2, 1) qc.draw(output=&#39;mpl&#39;) . . That&#39;s it, there are no more caveats. Thus, the total number of parameters we can get with $L$ CNOTs is $3n+4L$ and we need to describe a $d times d$ unitary which has $4^n$ parameters. In fact, the global phase of the unitary is irrelevant so we only need $3n+4L geq 4^n-1$. Solving for $L$ gives the TLB eqref{TLB}. That&#39;s pretty cool, isn&#39;t it? . Now there is an algorithm, called quantum Shannon decomposition (see ref), which gives an exact compilation of any unitary with the number of CNOTs twice as much as the TLB requires. In complexity-theoretic terms an overall factor of two is of course inessential, but for current NISQ devices we want to get as efficient as possible. Moreover, to my understanding the quantum Shannon decomposition is not easily extendable to restricted topology while inefficient generalizations lead to a much bigger overhead (roughly an order of magnitude). . What&#39;s in the preprint? . Templates . I&#39;ve already wrote an introduction way longer than intended so from now on I will try to be brief and to the point. The authors of the preprint propose two templates inspired by the quantum Shannon decomposition. The building block for each template is a &#39;CNOT unit&#39; . a1, a2 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;]] b1, b2 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.ry(a1, 0) qc.rz(a2, 0) qc.ry(b1, 1) qc.rx(b2, 1) qc.draw(output=&#39;mpl&#39;) . . First template is called sequ in the paper and is obtained as follows. There are $n(n-1)/2$ different CNOTs on $n$-qubit gates. We enumerate them somehow and simply stack sequentially. Here is a 3-qubut example with two layers (I use qiskit gates cz instead of our &#39;CNOT units&#39; for the ease of graphical representation) . qc = QuantumCircuit(3) for _ in range(2): qc.cz(0, 1) qc.cz(0, 2) qc.cz(1, 2) qc.barrier() qc.draw(output=&#39;mpl&#39;) . . The second template is called spin and for 4 qubits looks as follows . qc = QuantumCircuit(4) for _ in range(2): qc.cz(0, 1) qc.cz(1, 2) qc.cz(2, 3) qc.barrier() qc.draw(output=&#39;mpl&#39;) . . I&#39;m sure you get the idea. That&#39;s it! The templates fix the pattern of CNOTs while angles of single-qubit gates are adjustable parameters which are collectively denoted by $ theta$. . The idea now is simple. Try to optimize these parameters to achieve the highest possible fidelity for a given target unitary to compile. I am not at all an expert on the optimization methods, so I might miss many subtleties, but on the surface the problem looks rather straightforward. You can choose your favorite flavor of the gradient descent and hope for convergence. The problem appears to be non-convex but the gradient descent seems to work well in practice. One technical point that I do not fully understand is that the authors choose to work with fidelity defined by the Frobenius norm $||U-V||_F^2$ which is sensitive to the global phase of each unitary. To my understanding they often find that local minima of this fidelity coincides with the global minimum up to a global phase. OK, so in the rest of the post I refer to the &#39;gradient descent&#39; as the magic numerical method which does good job of finding physically sound minimums. . Results . Compiling random unitaries . OK, finally, for the surprising results. The authors find experimentally that both sequ and spin perform surprisingly well on random unitaries always coming very close to the TLB eqref{TLB} with good fidelity. More precisely, the tests proceed as follows. First, one generates a random unitary. Next, for each number $L$ of CNOTs below the TLB one runs the gradient descent to see how much fidelity can be achieved with this amount of CNOTs. Finally, one plots the fidelity as a function of $L$. Impressively, on the sample of hundred unitaries the fidelity always approaches 100% when the number of CNOTs reaches the TLB. For the $n=3$ qubits TLB is $L=14$, for $n=5$ $L=252$ (these are the two cases studied). So, in all cases studied, the gradient descent lead by the provided templates seems to always find the optimal compilation circuit! Recall that this is two times better than quantum Shannon decomposition. Please see the original paper for nice plots that I do not reproduce here. . Compiling on restricted topology . These tests were performed on the fully connected circuits. The next remarkable discovery is that restricting the connectivity does not to seem to harm the performance of the compilation! More precisely, the authors considered two restricted topologies in the paper, &#39;star&#39; where all qubits are connected to single central one and &#39;line&#39; where well, they are connected by links on a line. The spin template can not be applied to star topology, but it can be applied to line topology. The sequ template can be generalized to any topology by simply omitting CNOTs that are not allowed. Again, as examining a hundred of random unitaries on $n=3$ and $n=5$ qubits shows, the fidelity nearing 100% can be achieved right at the TLB in all cases, which hints that topology restriction may not be a problem in this approach at all! To appreciate the achievement, imagine decomposing each unitary via the quantum Shannon decomposition and then routing on restricted topology with swarms of SWAPs, a terrifying picture indeed. It would be interesting to compare the results against the performance of qiskit transpiler which is unfortunately not done in the paper to my understanding. . Compiling specific &#39;measure zero&#39; gates . Some important multi-qubit gates fall into the &#39;measure zero&#39; set which can be compiled with a smaller amount of CNOTs than is implied by the TLB eqref{TLB}. For example, 4-qubit Toffoli gate can be compiled with 14 CNOTs while the TLB requires 61 gates. Numerical tests show that the plain version of the algorithm presented above does not generically obtain the optimal compilation for special gates. However, with some tweaking and increasing the amount of attempts the authors were able to find optimal decompositions for a number of known gates such as 3- and 4-qubit Toffoli, 3-qubit Fredkin and 1-bit full adder on 4 qubits. The tweaking included randomly changing the orientation of some CNOTs (note that in both sequ and spin the control qubit is always at the top) and running many optimization cycles with random initial conditions. The best performing method appeared to be sequ with random flips of CNOTs. The whole strategy might look a bit fishy, but I would argue that it is not. My argument is simple: you only need to find a good compilation of the 4-qubit Toffoli once. After that you pat yourself on the back and use the result in all your algorithms. So it does not really matter how hard it was to find the compilation as long as you did not forget to write it down. . Compressing the quantum Shannon decomposition . Finally, as a new twist on the plot the authors propose a method to compress the standard quantum Shannon decomposition (which is twice the TLB, remember?). The idea seems simple and works surprisingly well. The algorithm works as follows. . Compile a unitary exactly using the quantum Shannon decomposition. | Promote parameters in single-qubit gates variables (they have fixed values in quantum Shannon decomposition). | Add LASSO-type regularization term, which forces one-qubit gates to have small parameters, ideally zero (which makes the corresponding gates into identities). | Run a gradient descent on the regularized cost function (fidelity+LASSO term). Some one-qubit gates will become identity after that (one might need to tune the regularization parameter here). | After eliminating identity one-qubit gates one can end up in the situation where there is a bunch of CNOTs with no single-qubit gates in between. There are efficient algorithms for reducing the amount of CNOTs in this case. | Recall that the fidelity was compromised by adding regularization terms. Run the gradient descent once more, this time without regularization, to squeeze out these last percents of fidelity. | From the description of this algorithm it does not appear obvious that the required cancellations (elimination of single-qubit gates and cancellations in resulting CNOT clusters) is bound to happen, but the experimental tests show that they do. Again, from a bunch of random unitaries it seems that the $ times 2$ reduction to the TLB is almost sure to happen! Please see the preprint for plots. . Weak spots . Although I find results of the paper largely impressive, a couple of weak spots deserve a mention. . Limited scope of experiments . The numerical experiments were only carried out for $n=3$ and $n=5$ qubits which of course is not much. To see if the method keeps working as the number of qubits is scaled is sure very important. There may be two promblems. First, the templates can fail to be expressive enough for larger circuits. The authors hope to attack this problem from the theoretical side and show that the templates do fill the space of unitaries. Well, best of luck with that! Another potential problem is that although the templates work fine for higher $n$, the learning part might become way more challenging. Well, I guess we should wait and see. . Unitary as the input . As I discussed somewhere way above, for a realistic quantum computation we can not know the unitary matrix that we need to compile. If we did, there would no need in the quantum computer in the first place. I can make two objects here. First, we are still in the NISQ era and pushing the existing quantum computers to their edge is a very important task. Even if an algorithm can be simulated classically, running it on a real device might be invaluable. Second, even quantum circuits on 1000 qubits do not usually feature 100-qubit unitaries. So it could be possible to separate a realistic quantum circuit into pieces, each containing only a few qubits, and compile them separately. . Final remarks . To me, the algorithms presented in the preprint seem to be refreshingly efficient and universal. At some level it appears to be irrelevant which exact template do we use. Near the theoretical lower bound they all perform similarly well, even on restricted topology. This might be a justification for choosing CNOT as the two-qubit gate, as this probably does not matter in the end! I&#39;m really cheering for a universal algorithm like that to win the compilation challenge over a complicated web of isolated heuristics, which are currently state of the art. .",
            "url": "https://idnm.github.io/blog/blog/machine%20learning/compilation/qiskit/paper%20review/2021/07/22/Machine-learning-compilation-of-quantum-circuits.html",
            "relUrl": "/machine%20learning/compilation/qiskit/paper%20review/2021/07/22/Machine-learning-compilation-of-quantum-circuits.html",
            "date": " • Jul 22, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "What is entanglement?",
            "content": "Introduction . I&#39;ve known the formal definition of entanglement for years, but I am only now appreciating many of its profound implications. In this post I would like to share two aspects that put entangled states into sharp contrast with unentangled (separable pure) states and classical random variables. Instead of proofs I provide references and simple experiments in qiskit. . . Entanglement is the failure of states to factorize . So what is entanglement? Entanglement is what entangled states have. What are those? Take two spins. The state . begin{equation} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) label{bell} end{equation}is your canonical example of an entangled stated. In contrast, all the states below are unentangled begin{align} | uparrow uparrow rangle, qquad | downarrow uparrow rangle, qquad frac1{ sqrt{2}}| uparrow rangle Big(| uparrow rangle-| downarrow rangle Big), qquad frac1{ sqrt{2}} Big(| uparrow rangle-| downarrow rangle Big) Big(| uparrow rangle+| downarrow rangle Big) label{unen} end{align} . The difference between eqref{bell} and eqref{unen} is the following. All latter states are actually products of the form $| psi_1 rangle | psi_2 rangle$ where $| psi_1 rangle$ is the state of the first system and $| psi_2 rangle$ of the second. In contrast, state eqref{bell} can not be represented in as a product. It is instead a linear combination of factorized states which is not reducible to a single product. You can define entangled states by this property of not being factorizible into states of consistuent spins. . Now that we know what entangled states are it is perfectly reasonable to ask: &quot;so what?&quot;. Why are entangled states special? I am going to give two angles on this questions, out of many possible. . . Note for the sake of concreteness and simplicity I talk about &quot;spins&quot;. In the context of discrete-variable quantum computation &quot;spin&quot;$ equiv$&quot;qubit&quot;, but I prefer spins, because they come with a useful geometrical intuition. The abstract Bloch sphere associated to a qubit describes an actual orientation of a spin in $3d$ space. . Entangled spin behaves very differently from unentangled . A spin which is not entangled can always be described by a direction $ bf n$ along which it is pointing $| uparrow_{ bf n} rangle$. If one measures the component of the spin along this direction, the result is always $ frac12$. Such a measurement corresponds to a projector $P({ bf n})={ bf n} cdot { bf sigma}=n_x sigma_x+n_y sigma_y+n_z sigma_z$. If state $| uparrow_{ bf n} rangle$ is measured along a different axis $ bf n&#39;$ the result depends on the angle $ theta$ between $ bf n$ and $ bf n&#39;$. With probability $ cos^2 frac theta2$ one gets projection $+ frac12$ and with probability $ sin^2 frac theta2$ one gets $- frac12$. However, for any state of the spin $| psi rangle$ there is an axis $ bf n$, such that measuring the spin along this axis gives $ frac12$ with probability one. . This is also true for any of the unentangled states eqref{unen}. For example, measuring the projection of the first spin in the state $| uparrow uparrow rangle equiv | uparrow_{ bf z} uparrow_{ bf z} rangle$ along $ bf z$ always gives $+ frac12$. As another example, since begin{align} | downarrow_{ bf x} rangle= frac12 Big(| uparrow_{ bf z} rangle-| downarrow_{ bf z} rangle Big) label{xdown} end{align} the state $ frac1{ sqrt{2}} Big(| uparrow rangle-| downarrow rangle Big) Big( uparrow rangle+| downarrow rangle Big)$ always registers $- frac12$ when the projection of the first spin along $ bf x$ axis is measured. . In contrast, for the maximally entangled state eqref{bell} the axis with a definite projection of the first spin does not exist. In fact, for all intents and purposes, if you only look at observables associated with the first qubit, state eqref{bell} behaves as a statistical ensemble of states $| uparrow rangle$ and $| downarrow rangle$, i.e. . begin{align} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) approx cases{| uparrow rangle text{ with probability $ frac12$} | downarrow rangle text{ with probability $ frac12$}} label{bellapprox} end{align}This means, for example, that projection onto $ bf z$ axis of the first spin is completely random: with probability $ frac12$ it behaves as $| uparrow rangle$ and gives projection $+ frac12$, with probability $ frac12$ it behaves as $| downarrow rangle$ and gives projection $- frac12$. This is different from a coherent superposition of the up and down states, such as eqref{xdown}. Although state eqref{xdown} gives random results when measured along $ bf z$, it gives certain results when measured along $ bf x$. There is no such axis for state eqref{bellapprox}. In fact, the spin projection along any axis is completely random. . To prove this fact I would need to go into some details of how one does construct an ensemble from an entangled state. This is not at all difficult but I won&#39;t do it here. I encourage an interested reader to consult John Preskill&#39;s notes (chapter 2.3). . Instead, let me do a quick experimental check using qiskit. A Hadamard gate followed by a CNOT creates our state eqref{bell}: . from qiskit import QuantumCircuit, BasicAer, execute from qiskit.visualization import plot_histogram qc = QuantumCircuit(2, 1) qc.h(0) qc.cx(0, 1) qc.draw(output=&#39;mpl&#39;) . To my knowledge, one can only measure in the computational basis in qiskit, i.e. only along $ bf z$ axis in our terminology. To measure a spin along some axis $ bf n$ we can instead rotate the spin itself, and then measure along $ bf z$ axis. Mathematically, if ${ bf n} = R^{-1} { bf z}$ for some rotation $R$ then $ langle uparrow_{ bf z}|P({ bf n})| uparrow_ rangle= langle uparrow_{R{ bf z}}|P({ bf z})| uparrow_{R{ bf z}} rangle$. . # Feel free to change them and see if the outcome distribution changes. theta, pi, lam = 0.13, 0.89, 0.37 qc.u(theta, pi, lam, 0) # Rotate the qubit. qc.measure(0, 0) # Execute on a simulator and plot a histogram of the result. backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=1000).result() counts = result.get_counts(qc) plot_histogram(counts) . The result looks like a fair sample from the uniform probability distribution. This means that projection on the axis we have specified is indeed random. You can try to change the axis and see if you can get a biased distribution (spoiler: you can not). . Entanglement correlations are stronger than classical . First let me note that although we talked about the first spin before, the state eqref{bell} is symmetric and everything equally applies to the second spin. Although the behavior of each of these spins is completely random, there are strong correlations between the them. If we can make local measurements on both spins the state eqref{bell} behaves as . begin{align} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) approx cases{| uparrow uparrow rangle text{ with probability $ frac12$} | downarrow downarrow rangle text{ with probability $ frac12$}} label{bellapprox2} end{align}So for example projections onto $ bf z$ axis of both spins are always the same, although random. Again, this in fact holds for any axis. Here is an experimental verification. . qc = QuantumCircuit(2, 2) qc.h(0) qc.cx(0, 1) # Rotation of each qubit to simulate measurement along arbitary axis. theta, pi, lam = 0.13, 0.89, 0.37 qc.u(theta, pi, lam, 0) qc.u(theta, pi, lam, 1) qc.measure([0, 1], [0, 1]) # Simulate and plot results. backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=2000).result() counts = result.get_counts(qc) plot_histogram(counts) . The result I get is almost certainly a uniform distribution of over $00=| uparrow_{ bf n} uparrow_{ bf n} rangle$ and $11=| downarrow_{ bf n} downarrow_{ bf n} rangle$ (you can change $ bf n$ by changing angles in the code), however I also get a tiny number of spurious counts for $01$ and $10$, which is probably a bug, hm. . When seeing this for the first time there is definitely something to contemplate, like say an EPR paradox. Spoiler: it is not possible to use these correlations for superluminal transmission of information, but they are still a valuable resource. I will discuss just one manifestation of these quantum correlations which has a very concrete operational interpretation -- it allows a quantum team to play a certain probabilistic game better than any classical team could! Note that this is also basically Bell&#39;s theorem in disguise. . So here is the setup. Alice and Bob are playing together against Charlie. Charlie sends random uncorrelated bits $x$ to Alice and $y$ to Bob. Admittedly, Charlie&#39;s job is not very creative and nothing in his strategy can be changed. Now, in response to the obtained bits Alice produces her output bit $a$ and Bob his $b$. Team A&amp;B wins if $a oplus b=x land y$ where $ oplus$ is XOR (sum modulo 2) and $ land$ is the logical AND. Explicitly, if $x land y=1$ both Alice and Bob got $x=y=1$ (which happens one quarter of the time) and they win iff they respond $a=0, b=1$ or $a=1, b=0$ so that $a oplus b=1$. For all other inputs from Charlie, i.e. when $(x,y)$ is equal to $(0,0), (1,0)$ or $(0,1)$ the logical sum $x land y=0$ and Alice and Bob win iff $a=0,b=0$ or $a=1, b=1$ so that $a oplus b=0$. . Now, although in the same team, Alice and Bob are not allowed to communicate during the game. But they can discuss their strategy in advance. The best that a classical team can do is to win $75 %$ of the time. To achieve this winning rate it is sufficient to simply output $a=0, b=0$ irrespective of Charlie&#39;s bits $x,y$. This strategy only loses when $x=y=1$, i.e. one quarter of the time. . Now comes the interesting part. If Alice and Bob each have a spin, and these spins are entangled as in state eqref{bell}, they can achieve the winning probability begin{align} P_{win}= frac12+ frac1{2 sqrt{2}} approx 0.85! label{pwin} end{align} So, what should they do? . Define four axes $ bf n_1,n_2,n_3,n_4$ in the $ bf xz$ plane (of course this is just one of the possibilities). Take ${ bf n_1}= (1,0)$, then ${ bf n_2}=( frac1{ sqrt{2}}, frac1{ sqrt{2}})$ is counter-clockwise rotated by $ pi/4$ wrt to $ bf n_1$; ${ bf n_3}=(0,1)$ is rotated by $ pi/2$; and finally ${ bf n_4}=(- frac1{ sqrt{2}}, frac1{ sqrt{2}})$ is rotated by $3 pi/4$. . . Now here is the strategy that Alice and Bob follow begin{align} a(x)= cases{P_{ bf n_3}, qquad x=0 P_{ bf n_1}, qquad x=1} qquad qquad b(y)= cases{P_{ bf n_2}, qquad y=0 P_{ bf n_4}, qquad y=1} label{abcases} end{align} . Where $P_{ bf n}=+1$ if Alice&#39;s (or Bob&#39;s) spin gave projection $+ frac12$ when measured along $ bf n$ and $P_{ bf n}=0$ if the projection was $- frac12$. An example: if Alice recieves $x=0$ and Bob $y=1$ Alice measures her spin along $n_3= bf z$ axis and sends back the result, while Bob measures his spin along $ bf{n_4}$ (which is $3 pi/4$ rotated $ bf x$ axis) and sends his result. . Now, shall we check that this strategy indeed achieves the advertised winning probability eqref{pwin}? Sure, I also thought so! . import numpy as np # Define rotation axes by their angles. theta1 = 0 theta2 = np.pi/4 theta3 = np.pi/2 theta4 = 3*np.pi/4 def charlie(): # Charlies job is to generate two random bits. return np.random.randint(0,1+1, size=(2)) def alice(x): # Alice decides on the measurement axis according to her strategy. if x==0: return theta3 if x==1: return theta1 def bob(x): # Bob does his part of the protocol. if x==0: return theta2 if x==1: return theta4 def one_round(): # First we prepare an entangled state. qc = QuantumCircuit(2, 2) qc.h(0) qc.cx(0, 1) # Now Charlie generates his bits. x, y = charlie() # A&amp;B team makes their move. a_angle = alice(x) b_angle = bob(y) # Again, we can not measure directly along the desired axes, # but must rotate the qubits instead. Rotation in the xz plane is made by `ry` gate. qc.ry(a_angle, 0) # Alice rotates her qubit. qc.ry(b_angle, 1) # Bob his. # Now we add measurments and actually run the circuit. qc.measure([0, 1], [0, 1]) backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=1).result() counts = result.get_counts(qc) # Output of counts is a dict like `{&#39;01&#39;: 1}`. This extracts the measurment results: a, b = [int(c) for c in list(counts.keys())[0]] # And now we check, team A&amp;B gogogo! return (a + b) % 2 == x * y . Alright, now let us collect the statistics: num_rounds = 2000 wins = 0 for _ in range(num_rounds): wins += one_round() print (&quot;Win probability:{}&quot;.format(wins/num_rounds)) . Win probability:0.847 . So that&#39;s pretty close to the theoretical value eqref{pwin}. Note that for each round of the game a new entangled pair is needed. . Now that we have seen that the strategy works let us briefly discuss why. I will only give a sketch and refer for details to Preskill&#39;s lectures chap 4.3. . One thing Alice and Bob could do is to always measure along the same axes. Then, their results would be perfectly correlated (i.e. they always output $a=b=0$ or $a=b=1$) which gives 0.75 winning probability, the same as the best deterministic strategy. Now, in one quarter of cases (when $x=y=1$) they are better off outputting anticorrelated results. If we revisit the figure above equation eqref{abcases} we see that the angle between $a(1)$ and $b(1)$ is $3 pi/4$ which indeed gives a negative correlation in this case $ Big( cos frac{3 pi}{4}=- frac{1}{ sqrt{2}} Big)$. The price to pay is that angles between $ Big(a(0),b(0) Big)$, $ Big(a(0),b(1) Big)$ and $ Big(a(1),b(0) Big)$ are now non-zero (and hence correlations are less than 1) which makes this strategy lose in some cases when the deterministic strategy wins. However, as we have seen experimentally the trade-off is still in our favor. It is also possible to prove that our choice of axes gives the maximum possible win probability. This is ultimately bound by Tsirelson&#39;s bound, see below. . Now you might ask -- what if there exists a clever randomized classical strategy which would perform better than deterministic 0.75 using a similar trick? Turns out this is not possible. The proof is based on the following inequality begin{align} Big| langle a_0 b_0 rangle+ langle a_0 b_1 rangle+ langle a_1 b_0 rangle- langle a_1 b_1 rangle Big| leq 2 end{align} which holds for any random variables $a_0, a_1, b_0, b_1$ taking values $ pm1$ and described by a joint probability distribution. This is known as CHSH inequality and a technical proof is trivial. Why quantum correlations do not have to obey the bound? Well, the reason is somewhat deep and quantum and ultimately related to Bohr&#39;s complementarity) -- non-commuting observables can not be simultaneously assigned values. That this statement has quantitative consequences is illustrated by Bell&#39;s theorem or our game. . Tehcnically quantum correlations obey the Tsirelson&#39;s bound begin{align} Big| langle a_0 b_0 rangle+ langle a_0 b_1 rangle+ langle a_1 b_0 rangle- langle a_1 b_1 rangle Big| leq 2 sqrt{2} end{align} which, as you see, is weaker by a factor $ sqrt{2}$, so the correlations themselves can be stronger, although still bounded. . Final remarks . Quantum entanglement is indeed very unusual and consequential. There are many more wonders that it entails, please consult your favorite lecture notes for a non-exhaustive list. My current favorite are John Preskill&#39;s lecture notes. For a non-mathematical although technically very accurate discussion of entanglement see this artice by Frank Wilczek entanglement made simple. . Any questions and suggestions are welcome, as this is my first blog demo. .",
            "url": "https://idnm.github.io/blog/blog/quantum%20concepts/qiskit/2021/07/12/Entanglement.html",
            "relUrl": "/quantum%20concepts/qiskit/2021/07/12/Entanglement.html",
            "date": " • Jul 12, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "How was this blog set up?",
            "content": "Why fastpages? . After deciding to start a scientific blog I was looking for an appropriate technical solution. My main requirements were . Ease of set up. | Ease of writing posts. | Decent support of $ LaTeX$. | Support of code snippets. | . After some search I decided to try out fastpages. I have a very limited understanding of the stack that fastpages use, so I treat it as a magic box. The magic box was easy for me to install while other bullet points are addressed all at once since fastpages allows to generate a post from a jupyter notebook. Although jupyter notebook is not exactly my favorite $ LaTeX$ editor it still much better than many other options and a good overall compromise. So essentially with fastpages you can write your posts in jupyter notebook, then commit to your github repository and the content will automatically be hosted at your domain on github pages. . Caveats . Following official installation worked smoothly for me. While customizing the blog further for my purposes there were several things that did not work right of the box of took some time to find out how to change: . Solved . I wanted to use numbered $ LaTeX$ equations with hyperlinks, which are not easily supported. This comment solved my problem! | You need to edit _pages/about.md to customize the way your &quot;about&quot; page is displayed. | To customize the front page you need to edit index.html. This is literally written on the front page of your blog, but I have not noticed it for a while. | Initially a lot of troubleshooting is needed to get the appearance of the blog I wanted. Commiting and waiting for the online web page to set up is super-slow. Here is an official guide on how to setup a live preview of your blog locally. One minor point that was a problem for me is that the default local server for blog preview https://127.0.0.1:4000 was not correct. After running sudo make server one of the outputs that jekyll produces is Server address: http://0.0.0.0:4000/blog/ which was the correct address for the live preview of my blog. | You need to do some work to make your site appear in google search results. This manual is very helpful, but a bit outdated: some of the things like generating sitemap.xml are now automated and do not require additional work as described in that post. | Not solved . On the web page the display equations of $ LaTeX$ have fluctuations in size which does not look good. |",
            "url": "https://idnm.github.io/blog/blog/fastpages/2021/07/11/How-this-blog-was-set-up.html",
            "relUrl": "/fastpages/2021/07/11/How-this-blog-was-set-up.html",
            "date": " • Jul 11, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "My name is Nikita Nemkov, I am a theoretical physicist diving into the field of quantum computation. On this blog I consolidate some of my thoughts on the subject, from reviews of the basic concepts to brief reports on the newest research papers. . I do not expect to have many readers and I do not tailor my posts to any particular audience. Perhaps the reader that could benefit from these notes the most is me, before writing them. Yet, if you found anything that I wrote useful give me a quick feedback in the comments or drop an email! .",
          "url": "https://idnm.github.io/blog/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://idnm.github.io/blog/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
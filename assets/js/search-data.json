{
  
    
        "post0": {
            "title": "Machine learning compilation of quantum circuits -- experiments",
            "content": "Introduction . from scipy.stats import unitary_group import matplotlib.pyplot as plt import jax.numpy as jnp import numpy as np from jax import random, value_and_grad, ops, jit, lax, vmap, grad, partial import optax key = random.PRNGKey(42) # !pip install tensornetwork # !pip install optax # !pip install qiskit # !pip install pylatexenc from qiskit import QuantumCircuit, transpile from qiskit.quantum_info import Operator, Statevector from qiskit.circuit import Parameter from qiskit.transpiler.passes.synthesis import UnitarySynthesis from qiskit.transpiler import PassManager from qiskit.converters import circuit_to_gate . . WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.) . Motivation . Ever since I read the paper by L.Madden and A.Simonetto (original preprint, my review) I knew I want to do this kind of experiments myself. At first I hoped that there is a well-developed software framework where I can easily build quantum circuits and then optimize them efficiently. However, I was not able to find a good fit for my problem. For example, to the best of my knowledge qiskit currently only provides acess to zero-order optimization routines. I later found quimb which might do what I want, but in the end I&#39;m glad I worked things out from scratch. Eventually I went for numpy+JAX combination which while being quite low-level was not a big problem to get working and shows a decent speed. I owe a ton to Ilia Luchnikov for introducing me to the framework and helping throught. . In this post I will give a walk thorough this implementation and show experiments with compilation of random unitaries. However, in my opinion truly interesting stuff is concerned with the compilation of special gates, say multi-controlled Toffolis on restricted connectivity. I intend to look at this kind problems in detail in a future blog post. You may wish to take a look at this preprint for advances in that direction. . NOTE:While I was working on my experiments another preprint appeared, by P.Rakyta and Z.Zimbor√°s, which is very similar to the work of M&amp;S in terms of numerical results. Despite the striking similarities these works are independent. As a bonus R&amp;Z also provide a numerical package SQUANDER that allows to play with their framework for compilation of unitaries. You might want to check that out if you are interested in doing some experiments yourself. . The problem . OK, so first a brief recap of what is the compilation problem. Given a quantum circuit we need to find an equivalent one, which satisfies certain requirements. A typical restrictions are to use only some specific two-qubits gates and to be compatible with limited connectivity. I gave a more detailed intro here. Here is a nearly-trivial example: a simple $CNOT$ gate . qc = QuantumCircuit(2) qc.cx(0, 1) qc.draw(output=&#39;mpl&#39;) . . can be decomposed in terms of the entangling $cz$ gate and single-qubit gates $rx, ry, rz$ as follows . qc_compiled = transpile(qc, basis_gates=[&#39;cz&#39;, &#39;rx&#39;, &#39;ry&#39;, &#39;rz&#39;], optimization_level=3) qc_compiled.draw(output=&#39;mpl&#39;) . . Now, for generic $n$-qubit unitaries one needs exponentially many entangling gates for the compilation. More precisely, there is a theoretical lower bound $ #CNOTs ge frac14 left(4^n-3n-1 right)$ on the amount of $CNOT$s required for compilation of any $n-$qubit unitary outside a measure zero set. Crucially, this measure zero set might in fact be of principal interest to quantum computing as it includes many operators featuring in most algorithms (such as multi-controlled gates). In this post I will only adress compilation of random unitaries and discuss compilation of special cases in a future post. For later reference here is the function computing the theoretical lower bound. . def TLB(n): return int((4**n-3*n-1)/4 + 1) for n in range(1, 7): print(&#39;TLB for {}-qubit unitary is {}&#39;.format(n, TLB(n))) . TLB for 1-qubit unitary is 1 TLB for 2-qubit unitary is 3 TLB for 3-qubit unitary is 14 TLB for 4-qubit unitary is 61 TLB for 5-qubit unitary is 253 TLB for 6-qubit unitary is 1020 . Now, there is an algorithm called quantum Shannon decomposition to decompose an arbitary $n$-qubit unitary into a sequence of $CNOT$s and single-qubit rotations which requires roughly twice as many $CNOT$s as the theoretical lower bound implies. In complexity-theoretic terms this is definitely good enoough, the overhead is just a small constant factor. However, for NISQ devices doubling the amount of gates is not a trivial matter. Is it possible to do better? . 3-qubit example . As papers M&amp;S and R&amp;Z show, one can do better and eliminate the 2x overhead, at least numerically. Namely, it seems that precisely at the theoretical lower bound the exact or nearly-exact compilation of any unitary is possible. Here is a real-life example. Consider the following 3-qubit circuit with $TLB(3)=14$ $CNOT$ gates . . The claim is that with the appropriate choice of angles in rotation gates it can morhp into any 3-qubit unitary (and in fact at least this many $CNOT$s are needed for almost all 3-qubit unitaries). To find the corresponding angles it is sufficient to run a numerical optimization minimizing the fidelity between this circuit&#39;s unitary and the target unitary. To me this is rather imressive, but raises several questions. Why choose $CNOT$ gates of all entangling gates? Why place them in that exact order as shown at the figure? It appears to be an empirical fact that precise location of entangling gates as well as their choice ($CNOT$, $cz$, etc) makes little difference. Moreover, even restricted connectivity does not seem to force an overhead for compilation. It is my main goal to back up these claims with numerical experiments in an interactive way. In particular, I will illustrate the following points. . Exactly at the theoretical lower bound a nearly-exact compilation seems to always be possible (at least for up to 6 qubits). This is a 2x improvement over the best theoretical decomposition. | Both $cz$ and $CNOT$ gates perform equally well. It is tempting to guess that any entangling gate will perform similarly. | The maximum fidelity is a monotonic function of the number of entangling gates. This implies that simply counting 2-qubit gates gives a good measure of circuits expressivity. | The most remarkable for me is the fact that even a restricted topology seems to cause no overhead on compilation cost. I will show that even on a chain topology the same amount of $CNOT$s is sufficient to reach good fidelity. | What you&#39;ll find if you keep reading . The rest of this post is divided into two parts. In the first I write some numpy/JAX/qiskit code that allows to construct and efficiently optimize parametrized circuits. I try to give some explanations of the underlying numerical framework, but please take into account that my own understanding is rather limited. Still, the resulting performance seems to be good enough to reproduce results of the existing preprints. I advise to skip this part if you are only interested in the results. . In the second part of the post I will do a number of experiments compiling random unitaries with varying numbers of qubits, different types of entangling gates, restricted connectivity and try to draw some general lessons from them. I tried to make this part independent of the first, although I didn&#39;t stop all the implementation details from sinking trough. . NOTE:This blog post is also a fully functional jupyter notebook. You can open it in Colab or download locally and perform more experiments yourself! . Numerical framework . Entangling blocks . First let us define the basic 1- and 2-qubit gates in matrix form. For now you can safely ignore the use jnp arrays instead of np arrays. . # Controlled-NOT (or controlled-X gate) cx_mat = jnp.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]) # Controlled-Z gate cz_mat = jnp.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, -1]]) # Pauli matrices x_mat = jnp.array([[0, 1], [1, 0]]) y_mat = jnp.array([[0, -1j], [1j, 0]], dtype=jnp.complex64) z_mat = jnp.array([[1, 0], [0, -1]]) # Rotation gates def rx_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*x_mat*jnp.sin(a/2) def ry_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*y_mat*jnp.sin(a/2) def rz_mat(a): return jnp.cos(a/2)*jnp.identity(2)-1j*z_mat*jnp.sin(a/2) . The circuits that we are going to train will be built out of two types of 2-qubit blocks, the controlled-Z and the controlled-NOT. Here are the definitions: . class block(): &quot;&quot;&quot;Two-qubit entangling block. Methods: circuit: gives equivalent `qiskit` circuit. unitary: gives `jax.numpy` unitary matrix of the circuit. &quot;&quot;&quot; def __init__(self, gate_name, angles): self.gate_name = gate_name self.angles = angles def circuit(self): &quot;&quot;&quot;Quantum circuit in `qiskit` corresponding to our block.&quot;&quot;&quot; qc = QuantumCircuit(2) if self.gate_name == &#39;cx&#39;: qc.cx(0, 1) elif self.gate_name == &#39;cz&#39;: qc.cz(0, 1) else: print(&quot;Gate &#39;{}&#39; not yet supported&#39;&quot;.format(self.gate_name)) angles = np.array(self.angles) # convert from JAX array to numpy array if applicable. qc.ry(angles[0], 0) qc.rx(angles[1], 0) qc.ry(angles[2], 1) qc.rx(angles[3], 1) return qc def unitary(self): &quot;&quot;&quot;JAX-compatible unitary corresponding to our block.&quot;&quot;&quot; if self.gate_name == &#39;cx&#39;: entangling_matrix = cx_mat elif self.gate_name == &#39;cz&#39;: entangling_matrix = cz_mat else: print(&quot;Gate &#39;{}&#39; not yet supported&#39;&quot;.format(self.gate_name)) x_rotations = jnp.kron(rx_mat(self.angles[1]), rx_mat(self.angles[3])) y_rotations = jnp.kron(ry_mat(self.angles[0]), ry_mat(self.angles[2])) return x_rotations @ y_rotations @ entangling_matrix . Here is how they look: cz block . a0, a1, a2, a3 = [Parameter(a) for a in [&#39;a0&#39;, &#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] block(&#39;cz&#39;, [a0, a1, a2, a3]).circuit().draw(output=&#39;mpl&#39;) . and cx block . block(&#39;cx&#39;, [a0, a1, a2, a3]).circuit().draw(output=&#39;mpl&#39;) . Our block class can return a qiskit circuit and the corresponding unitary matrix. Of course we could have extracted the unitary from the circuit itself via qiskit API, but this would make the matrix representation incompatible with JAX which will be our workhorse for optimization. To the best of my knowledge currently it is only possible to use zero-order methods directly from qiskit which is a serious limitation. So at this point we needed a bit of wheel reinvention. Let&#39;s check that our implementation is consistent with qiskit: . angles = random.uniform(random.PRNGKey(0), shape=(4,), minval=0, maxval=2*jnp.pi) for gate in [&#39;cx&#39;, &#39;cz&#39;]: b = block(gate, angles) qc = b.circuit() qs_unitary = Operator(qc.reverse_bits()).data # Yes, we need to reverse bits in qiskit to match our conventions. our_unitary = b.unitary() print(&#39;qiskit unitary is the same as our unitary for block with gate {}: {}&#39;.format(gate, jnp.allclose(qs_unitary, our_unitary))) . qiskit unitary is the same as our unitary for block with gate cx: True qiskit unitary is the same as our unitary for block with gate cz: True . To match matrix representations of quantum circuits might be a headache as I discussed in another post, so this was a necessary check to do. . Our two building blocks (cz and cx) only differ by the type of the two-qubit gate. The circuits that we are going to build seem to do equally well for any choice of two-qubit gate. I will mostly use cz gate because it is symmetric under the swap of qubits, but I will also occasionally bring up the cx gate to illustrate that it has the same performance. Angles $a_0$-$a_3$ are going to be optimized. . Optimization with JAX . A word about JAX . What is JAX? Well, I personally think of it as numpy on steroids. You can check out the official documentation or numerous nice overwievs on the web. For our purposes two key features of JAX are . Autograd. | JIT or just-in-time compilation. | Autograd allows to define functions the same way you do in numpy and have analytic derivatives available with no extra coding on your side. At the moment grad function can only be applied to real scalars. For example, let us define the absolute value of the trace of cx block as function of rotations gate angles . def block_tr_abs(angles): b = block(&#39;cx&#39;, angles) tr = jnp.trace(b.unitary()) return jnp.abs(tr) . Since everything so far has been defined using jax.numpy we have immediate access to the gradient of this function . grad(block_tr_abs)([0.,1.,2.,3.]) . [DeviceArray(0.03655498, dtype=float32), DeviceArray(-0.25903472, dtype=float32), DeviceArray(-0.7384602, dtype=float32), DeviceArray(-7.450581e-09, dtype=float32)] . Autograd feature of JAX allows us to just define the loss function associated with our circuit in plain numpy terms and use advanced first-order optimizers such as Adam out of the box. . The next crucial ingredient is jit-compilation. When used with a bit of care, it allows to speed up evaluation of similar expression by orders of magnitude. For example let us compare runtimes of the jitted and unjitted versions of our trace function. Let&#39;s first define a sample of random angles . test_angles = random.uniform(random.PRNGKey(0), shape=(1000, 4), minval=0, maxval=2*jnp.pi) . and now time evaluation of unjitted trace function . %%time for angles in test_angles: block_tr_abs(angles) . CPU times: user 12.1 s, sys: 1.07 s, total: 13.1 s Wall time: 11 s . Now awe to the power of jit! . %%time jit_block_tr_abs = jit(block_tr_abs) for angles in test_angles: jit_block_tr_abs(angles) . CPU times: user 160 ms, sys: 7.73 ms, total: 168 ms Wall time: 147 ms . What happened here is that during the first call to the jitted function it&#39;s efficient XLA version was compiled and then used to evaluate all subsequent calls. . Gradient descent . We will use the following measure of discrepancy between two unitaries $disc(U, V) = 1- frac1{N} operatorname{Tr} left( U^ dagger V right)$ where $U,V$ are $N times N$ matrices. It is normalized so that $disc(U,U)=0$ and $disc(U,V)=0$ when $U$ and $V$ are orthogonal. Note that this measure is insensitive to global phases. . def disc(U, U_target): n = U_target.shape[0] return 1-jnp.abs((U.conj() * U_target).sum())/n . Here is the optimization routine that we are going to use. It is pretty straightforward and I will not give much explanations, but illustrate with an example. . @partial(jit, static_argnums=(0, 1, )) # &lt; Here is where the magic happens! # Remove this line and everything will run 1000 times slower:) def unitary_update(loss_and_grad, opt, opt_state, angles): &quot;&quot;&quot;Single update step.&quot;&quot;&quot; loss, grads = loss_and_grad(angles) updates, opt_state = opt.update(grads, opt_state) angles = optax.apply_updates(angles, updates) return angles, opt_state, loss def unitary_learn(U_func, U_target, n_angles, init_angles=None, key=random.PRNGKey(0), learning_rate = 0.01, num_iterations=5000, target_disc = 1e-10): &quot;&quot;&quot;Use Adam optimizer to minimize discrepancy between pamaterzied unitary and targe unitary. Args: U_func: function of angles returning univary matrix. U_target: unitary matrix to approximate. n_angles: total number of angles (parameters) in U_func. init_angles: intial angles for gradient descent. If not provided chosen at random. key: random seed to use for inizialization of initial angles. learning_rate: learning rate in Adam optimizer. num_iterations: maximum number of iterations. target_disc: stop optimization if discrepancy drops below target_disc. Returns: tuple (angles_history, loss_history) where angles_history: list of angles (parameters) at each iteration step. loss_history: values of loss_function at each iteration step. &quot;&quot;&quot; # If initial angles are not provided generate them at random. if init_angles is None: key = random.PRNGKey(0) angles = random.uniform(key, shape=(n_angles,), minval=0, maxval=2*jnp.pi) else: angles = init_angles # Loss function to minimize is dicrepancy defined above. loss_func = lambda angles: disc(U_func(angles), U_target) loss_and_grad = value_and_grad(loss_func) # Optimizer is taken from the `optax` library and its use is self-explanotory. opt = optax.adam(learning_rate) opt_state = opt.init(angles) # Optimization cycle angles_history=[] loss_history=[] for _ in range(num_iterations): angles, opt_state, loss = unitary_update(loss_and_grad, opt, opt_state, angles) angles_history.append(angles) loss_history.append(loss) if loss &lt; target_disc: break return angles_history, loss_history . OK, now a very simple example. Say we want to find a $ZXZ$ decomposition of $Y$-gate. Define: . def zxz_ansatz(angles): return rz_mat(angles[0]) @ rx_mat(angles[1]) @ rz_mat(angles[2]) . Learning is now very simple: we give unitary_learn the ansatz unitary as function of angles, the target unitary and also explicitly the number of parameters to be trained: . angles_history, loss_history = unitary_learn(zxz_ansatz, y_mat, 3) . We can visualize the learning progress as follows: . plt.plot(loss_history) plt.yscale(&#39;log&#39;) . The learned angles in $ZXZ$ decomposition are . angles_history[-1] . DeviceArray([6.59216 , 3.1411407, 3.4505684], dtype=float32) . It is not difficult to check directly that the result is equal to the $Y$ matrix up to a global phase with reasonable accuracy, indeed . jnp.around(1j*zxz_ansatz(angles_history[-1]), 3) . DeviceArray([[0.+0.j, 0.-1.j], [0.+1.j, 0.+0.j]], dtype=complex64) . Quantum circuits with numpy . Now it&#39;s time to build full quantum circuits. We will think of a quantum circuit on $n$ qubits as a tensor with $2*n$ legs. First $n$ legs correspond to output and last to $n$ input. This is illustrated at the picture. . . It is natural for input legs to be on the left because in matrix notation a unitary $U$ acts on a state $ psi$ by left multiplication $U psi$. On the other hand note that quantum circuits are usually drawn left-to-right and to compare the two descriptions a left-right reflection must be made. . Suppose now that given an $n-$qubit circuit $U$ we want to append an additional $m-$qubit gate $V$ at the end. Here is a concrete example (a picture is worth a thousand words!) . Several things to keep in mind: . To append gate $V$ at the end in quantum circuit notation, we need to draw it on the left here. | Tensor legs are joined by numpy&#39;s tensordot operation. Which axes to contract is clear from the picture -- we need to join axes 2, 3 of $V$ to 1, 3 of $U$. | In the resulting tensor the output legs are not in the correct order. Instead of being numbered from top to bottom after tesordot first several axes are those of $V$ and the remaining are uncontracted output axes of $U$ (take a look at the leftmost column of numbers). This needs to be corrected by explicit transposition of output axes. | The final caveat is that if some of the legs connecting gate to the circuit are twisted the output legs needs to be transposed accordingly. Here is an example | . Here is the code that implements this program. . def gate_transposition(placement): &quot;&quot;&quot;Determine transposition associated with initial placement of gate.&quot;&quot;&quot; position_index = [(placement[i], i) for i in range(len(placement))] position_index.sort() transposition = [i for _,i in position_index] return transposition def transposition(n_qubits, placement): &quot;&quot;&quot;Return a transposition that relabels tensor axes correctly. Example (from the figure above): n=6, placement=[1, 3] gives [2, 0, 3, 1, 4, 5]. Twiseted: n=6, placement=[3, 1] gives [2, 1, 3, 0, 4, 5].&quot;&quot;&quot; gate_width = len(placement) t = list(range(gate_width, n_qubits)) for position, insertion in zip(sorted(placement), gate_transposition(placement)): t.insert(position, insertion) return t def apply_gate_to_tensor(gate, tensor, placement): &quot;&quot;&quot;Append `gate` to `tensor` along legs specified by `placement`. Transpose the output axes properly.&quot;&quot;&quot; gate_width = int(len(gate.shape)/2) tensor_width = int(len(tensor.shape)/2) # contraction axes for `tensor` are input axes (=last half of all axes) gate_contraction_axes = list(range(gate_width, 2*gate_width)) contraction = jnp.tensordot(gate, tensor, axes=[gate_contraction_axes, placement]) # input(=last half) indices are intact t = transposition(tensor_width, placement) + list(range(tensor_width, 2*tensor_width)) return jnp.transpose(contraction, axes=t) . Now, using this tensor language we will construct unitary matrices corresponding to our ansatz circuits. To specify the ansatz we must supply the number of qubits in the circuit, type of entangling blocks to use and arrangement of these blocks. . The simplest way to specify arrangement would be to just give a list like [[0,1], [1, 3], [2, 1]] etc of pairs of qubits to put entangling blocks on to. However for performance reasons I need to make it more complicated. To construct a matrix for our quantum circuit we basically need to loop over all entangling gates and append them one by one. When using JAX plain python loops are simply unrolled and then compiled. For large loops this leads to very large compilation times. If there is no structure in how we place our gates in the circuit this is probably the best one can do. However, we can be more efficient than that if there is a structure. Take a look at this picture . qc = QuantumCircuit(4) i = 0 for _ in range(11): qc.cx(i,i+1) i = (i+1) % 3 if i % 3 == 0: qc.barrier() qc.draw() . . ‚ñë ‚ñë ‚ñë q_0: ‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îå‚îÄ‚î¥‚îÄ‚îê q_1: ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê q_2: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚îÄ‚ñ†‚îÄ‚îÄ‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îå‚îÄ‚î¥‚îÄ‚îê ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò q_3: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ X ‚îú‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚ñë ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚ñë . Here $CNOT$s are just placeholders for any entangling block of our interest. There is a regular pattern. Most of the circuit consists of identical layers up to a couple of final gates. Construction and optimization of such circuits with JAX can be made way more efficient by using lax.fori_loop (see here for docs) or a similar construct. This allows to exploit the regularity and reduce the compilation time dramatically. . The price to pay is a bit of a hassle in separating all gates into regular ones and the remainder. My core function build_unitary accepts the regular layers as an argument layer_placements=[layer, number_of_repetitions] and the remainder gates are described by free_placements. Also, we need some way to access all parameters (angles) in our circuit. I chose the simplest approach here, to supply angles as a 1d array, but internally they play a bit different roles so there is also a function split_angles to separate a 1d array of all angles into several logical blocks. . OK, so here is the code. Examples are found in the end of this section. . def split_angles(angles, num_qubits, layer_len, num_layers, free_placements_len): &quot;&quot;&quot;Splits 1d array of all angles in a circuit into four groups. Args: angles: all angles in a circuit as 1d array. num_qubits: number of qubits in a circuit. layer_len: length (depth) of a single layer in a circuit. num_layers: number of repeated layers. free_placements_len: number of entanglig blocks not in layers. Returns: a tuple (surface_angles, layers_angles, free_block_angles) where surface_angles: angles in initial single-qubit blocks. block_angles: angles of all entangling blocks. layers_angles: angles for entangling blocks that are parts of complete layers. free_block_angles: angles of remaining entangling blocks. &quot;&quot;&quot; surface_angles = angles[:3*num_qubits].reshape(num_qubits, 3) block_angles = angles[3*num_qubits:].reshape(-1, 4) layers_angles = block_angles[:layer_len*num_layers].reshape(num_layers, layer_len, 4) free_block_angles = block_angles[layer_len*num_layers:] return surface_angles, block_angles, layers_angles, free_block_angles def build_unitary(num_qubits, block_type, angles, layer_placements=[[], 0], free_placements=[]): &quot;&quot;&quot; Builds `JAX`-compatible unitary matrix of a quantum circuit. Arguments specify structure of the circuit and values of parameters. Args: num_qubits: number of qubits. block_type: type of entangling block to use. Currently only &#39;cx&#39; and &#39;cz&#39; are supported. angles: 1d array of all angle parameters in the circuit. layer_placements: a tuple (single_layer, n) where `single_layer` specifies positions of several entangling blocks and `n` how many time to repeat each layer. free_placements: Positions of entangling blocks that do no belong to layers. Returns: A `jax.numpy` unitary matrix of the quantum circuit. &quot;&quot;&quot; layer, num_layers = layer_placements layer_depth = len(layer) num_blocks = len(layer)*num_layers+len(free_placements) # Count all entangling blocks. # Divides 1d array of all angles into three logically distinct groups. surface_angles, _, layers_angles, free_block_angles = split_angles(angles, num_qubits, len(layer), num_layers, len(free_placements)) # Initizlizes identity matrix of the proper size. u = jnp.identity(2**num_qubits).reshape([2]*num_qubits*2) # Unitary matrix is built in three steps. # First, 3 single-qubit gates are applied to each qubit. # Second, all entangling blocks that are parts of layers are applied. # Finally, remainder blocks that a not parts any layer are applied. # Initial round of single-qubit gates for i, a in enumerate(surface_angles): gate = rz_mat(a[2]) @ rx_mat(a[1]) @ rz_mat(a[0]) u = apply_gate_to_tensor(gate, u, [i]) # Sequence of layers wrapped in `fori_loop`. # Using `fori_loop` instead of plain `for` loop reduces the compilation time significantly. # To use `fori_loop` it is convenient to define a separate function that applies a whole layer of gates. def apply_layer(i, u, layer, layers_angles): &quot;&quot;&quot;Apply several gates to a given quantum circuit. Supplying the totality of `layers_angles` makes the function compatible with `fori_loop`. Args: i: index of the layer. u: matrix to apply gates to. layer: positions of all gates to be applied. layers_angles: angles of all layers. &quot;&quot;&quot; layer_angles = layers_angles[i] for block_angles, position in zip(layer_angles, layer): gate = block(block_type, block_angles).unitary().reshape(2,2,2,2) u = apply_gate_to_tensor(gate, u, position) return u if num_layers&gt;0: u = lax.fori_loop(0, num_layers, lambda i, u: apply_layer(i, u, layer, layers_angles), u) # Adds the remainding (free) entangling blocks. for angles, position in zip(free_block_angles, free_placements): gate = block(block_type, angles).unitary().reshape(2,2,2,2) u = apply_gate_to_tensor(gate, u, position) return u.reshape(2**num_qubits, 2**num_qubits) . Layers . Here are a couple of simple functions to help define gate arrangements. The basic layer is sequ_layer which consists of entangling gates applied to each possible pair of two qubit gates enumerated by pairs $(i,j)$ with $i&lt;j$. . def sequ_layer(num_qubits): return [[i,j] for i in range(num_qubits) for j in range(i+1, num_qubits)] def fill_layers(layer, depth): num_complete_layers = depth // len(layer) complete_layers = [layer, num_complete_layers] incomplete_layer = layer[:depth % len(layer)] return complete_layers, incomplete_layer . Function fill_layers allows to specify how much entangling gates we want in total and splits them into complete layers (to be used as layer_placements) and possible remainder gates (that become free_placements). For example, a sequ_layer on three qubits consists of three gates at positions . sequ_layer(3) . [[0, 1], [0, 2], [1, 2]] . If we want to have the sequ pattern and 10 entangling gates in total we can put three complete layers and a final single gate. fill_layers does just that . layer_placements, free_placements = fill_layers(sequ_layer(3), 10) print(layer_placements) print(free_placements) . [[[0, 1], [0, 2], [1, 2]], 3] [[0, 1]] . Packing everything together: ansatz circuits . Now that we have defined our building blocks and convenience functions to assemble them it is time to pack everything together and reap the harvest. . I will define ansatz class that assembles our building blocks according to a predefined pattern. It&#39;s circuit method gives a qiskit circuit which can be used for visualization and cross-checks. It&#39;s unitary attribute returns fully jax-compatible matrix representation of the same circuit. Finally, its learn method uses our optimization routine to approximate a target unitary. First the code, then an example. . class Ansatz(): &quot;&quot;&quot;Parametric quantum circuit. Ansatz/parametric circuit is defined by tupes of entangling blocks and their arrangement. Concrete values of parameters are not considered part of the ansatz. Class provides access to both `qiskit` version of the circuit and `jax.numpy` unitary matrix. Attributes: num_qubits: number of qubits block_type: type of entangling blocks num_angles: total number of angles (parameters) in the circuit. unitary: `jax.numpy` unitary matrix of the circuit as function of angles. Methods: circuit: `qiskit` version of the circuit. learn: numerical approximation of the target unitary. &quot;&quot;&quot; def __init__(self, num_qubits, block_type, layer_placements=[[], 0], free_placements=[]): self.num_qubits = num_qubits self.block_type = block_type self.layer, self.num_layers = layer_placements self.free_placements = free_placements self.all_placements = self.layer*self.num_layers+free_placements self.num_angles = 3*num_qubits+4*len(self.all_placements) self.unitary = lambda angles: build_unitary(self.num_qubits, self.block_type, angles, layer_placements=[self.layer, self.num_layers], free_placements=self.free_placements) def circuit(self, angles=None): &quot;&quot;&quot;qiskit version circuit. If angles not specified a parametric circuit is constructed.&quot;&quot;&quot; if angles is None: angles = np.array([Parameter(&#39;a{}&#39;.format(i)) for i in range(self.num_angles)]) surface_angles, block_angles, _, _ = split_angles(angles, self.num_qubits, len(self.layer), self.num_layers, len(self.free_placements)) qc = QuantumCircuit(self.num_qubits) # Initial round of single-qubit gates. for n, a in enumerate(surface_angles): qc.rz(a[0], n) qc.rx(a[1], n) qc.rz(a[2], n) # Entangling gates accoring to placements for a, p in zip(block_angles, self.all_placements): qc_block = block(self.block_type, a).circuit() qc = qc.compose(qc_block, p) return qc def learn(self, u_target, **kwargs): &quot;&quot;&quot;Use numerical optimization to approximate u_target.&quot;&quot;&quot; u_func = self.unitary return unitary_learn(u_func, u_target, self.num_angles, **kwargs) . Here is an example that should illustrate how all this can be used. . n_qubits = 3 block_type = &#39;cx&#39; # For technical reasons all entangling gates are divided into &#39;layers&#39; and &#39;free&#39; gates. single_layer = [[0, 1], [2, 1]] # We make single layer consisting of &#39;cx&#39; block on qubits [0,1] # followed by reversed &#39;cx&#39; block on qubits [1,2]. layers = [single_layer, 3] # The layer is repeated 3 times. free_placements = [[1, 0], [0, 1], [1, 2], [2, 1]] # Apeend remaining `free placements` a. anz = Ansatz(n_qubits, block_type, layer_placements=layers, free_placements=free_placements) . Here is what resulting circuit looks like. . anz.circuit().draw(output=&#39;mpl&#39;) . Just to make sure let us check that the unitary matrix of this circuit extracted from qiskit agrees with our own implementation for a random set of angles. . angles = random.uniform(random.PRNGKey(0), shape=(anz.num_angles,), minval=0,maxval=2*jnp.pi) qs_u = Operator(anz.circuit(angles).reverse_bits()).data # qiskit matrix representation our_u = anz.unitary(angles) # our matrix representation print(jnp.allclose(qs_u, our_u, rtol=1e-6, atol=1e-7)) . True . Experiments . Now that the hard work is behind we can sit back and reap the benefits. I will go through a series of examples. Primary goal is to back up the claims from the introduction about reaching the theoretical lower bound, agile performance on restricted topology etc. But I will also try to make clear how my code can be used if you wish to do a little experimenting with it yourself. . Learning 2-qubit random unitary . Let&#39;s start by learning a random 2-qubits unitary. First, define one. . u_target = unitary_group.rvs(4, random_state=0) . Here is the parametrized circuit we are going to use. cz means that the entangling gate is controlled-Z while free_placements are just positions where to put these entangling gates. There isn&#39;t much choice for 2 qubits as you could guess. I will explain why I call these free_placements a bit later. . anz = Ansatz(2, &#39;cz&#39;, free_placements=[[0,1], [0,1], [0, 1]]) anz.circuit().draw(output=&#39;mpl&#39;) # anz.circuit() is a fully-functional `qiskit` version of our ansatz. . The learning process is easy as pie: %%time angles_history, loss_history = anz.learn(u_target) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 2.22 s, sys: 19.8 ms, total: 2.24 s Wall time: 2.19 s . The graph shows that we achieve great fidelity in under 500 iterations. . Don&#39;t believe me? Is there a way to tell if this plot indeed reflects a successful compilation without looking under the hood? OK OK, since you&#39;re asking, I will double-check using pure qiskit: . angles = angles_history[-1] # Last(=best) angles in the optimization process. qc = anz.circuit(angles) # genuine qiskit circuit. u_qs = Operator(qc.reverse_bits()).data # qiskit API to extract the unitary matrix. disc(u_qs, u_target) # OK, I guess here you have believe I&#39;ve implemented the cost function properly. # If you want to compare the matrices component-wise, fine with me. . DeviceArray(2.3841858e-07, dtype=float32) . Similar checks can be done in more complicated scenarios below. . You can move forward to other examples or try some experiments here. Some ideas: . Changing gate type from cz to cx (should not affect the result). | Decreasing the number of layers (fidelity won&#39;t be nearly as good). | Increasing the number of layers (same fidelity with less iterations). | Learning 3-qubit random unitary . I advertised in the introduction that with just 14 entangling gates any 3-qubit unitary can be nearly perfectly approximated. Let me back up this claim. Here is how we can construct the corresponding ansatz. . num_qubits = 3 block_type = &#39;cz&#39; depth = 14 layer_placemets, free_placements = fill_layers(sequ_layer(num_qubits), depth) anz = Ansatz(num_qubits, block_type, layer_placements=layer_placements, free_placements=free_placements) anz.circuit().draw(output=&#39;mpl&#39;) . The way gate placements are passes to Ansatz here require a bit of unpacking. This is an implementation detail I didn&#39;t take enough care to hide. For technical reasons I explained in the numerical section optimization is much faster when gates are arranged in a regular pattern. The pattern we use here is called sequ_layer and for three qubits it is simply . sequ_layer(num_qubits) . [[0, 1], [0, 2], [1, 2]] . i.e. it just lists all possible pairs of three qubits. However, since 14 % 3 = 2 the two last gates do not fit into the regular pattern and require a bit of a special treatment. This is what the function fill_layers does for us. Indeed . layer_placements, free_placements = fill_layers(sequ_layer(num_qubits), depth) print(&#39;basic layer is repeated four times:&#39;, layer_placements) print(&#39;remaining blocks reside at positions:&#39;, free_placements) . basic layer is repeated four times: [[[0, 1], [0, 2], [1, 2]], 4] remaining blocks reside at positions: [[0, 1], [0, 2]] . I hope that did explain the way that gate positions are passed to the Ansatz. Instead of sequ_layer you can pass any arrangment of gates to be periodically repeated. We will do just that when considering a restricted topology. . Now let&#39;s run the optimization. . %%time u_target = unitary_group.rvs(2**num_qubits, random_state=0) angles_history, loss_history = anz.learn(u_target) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 9.18 s, sys: 194 ms, total: 9.37 s Wall time: 8.55 s . OK, I hope this does convince you that our ansatz was indeed good enough! Another interesting thing to do is to make a sweep to see how the fidelity increases (error drops) with the number of layers. . %%time best_loss = [[], []] for depth in range(14): # TLB(3)=14 layer_placemets, free_placements = fill_layers(sequ_layer(n_qubits), depth) for i, block_type in enumerate([&#39;cx&#39;, &#39;cz&#39;]): anz = Ansatz(num_qubits, block_type, layer_placements=layer_placemets, free_placements=free_placements) angles, loss_history = anz.learn(u_target, target_disc=10e-4) best_loss[i].append(min(loss_history)) plt.plot(best_loss[0], label=&#39;cx loss&#39;) plt.plot(best_loss[1], label=&#39;cz loss&#39;) plt.ylabel(&#39;error&#39;) plt.xlabel(&#39;number of entangling gates&#39;) plt.legend() . CPU times: user 3min 45s, sys: 6.05 s, total: 3min 51s Wall time: 3min 30s . &lt;matplotlib.legend.Legend at 0x7f73e51d0be0&gt; . One lesson here is that both types of two-qubits gate perform similarly well at all depths. This is not surprising for because cx and cz gates can be related by single-qubit Hadamard transformations. It would be interesting to see if other two-qubit gates perform differently. . Another important observation is that the best fidelity is a monotonic function of the the amount of two-qubit gates. There is some work on variational algorithms testing various metrics that would adequately reflect expressivity of the ansatz. I think that plain number of $CNOT$ gates should in fact be a fantastic and simple metric for this. . Learning 6-qubit random unitary . I do know that 3 is followed by 4, but shall we perhaps get more ambitious? Let&#39;s try to compile a 6-qubit random unitary (you can try to go higher if your machine allows): . %%time num_qubits = 6 depth = TLB(num_qubits) # 1020 for 6 qubits layer_placements, free_placements = fill_layers(sequ_layer(num_qubits), depth) u_target = unitary_group.rvs(2**num_qubits, random_state=0) anz = Ansatz(num_qubits, &#39;cz&#39;, layer_placements=layer_placements, free_placements=free_placements) angles_history, loss_history = anz.learn(u_target, num_iterations=5000) plt.title(&#39;number of qubits: {}&#39;.format(num_qubits)) plt.xlabel(&#39;number of iterations&#39;) plt.ylabel(&#39;error&#39;) plt.plot(loss_history) plt.yscale(&#39;log&#39;) . CPU times: user 5min 36s, sys: 58.7 s, total: 6min 34s Wall time: 6min 29s . Note that depth of the theoretical lower bound for 6 qubits is $TLB(6)=1020$ which implies that there are $ approx 4000$ parameters in our ansatz. On my modest laptop the training completes in about 10 minutes. Of course I would not claim this to be the cutting edge, but our JAX setup seems to be competitive at the scale (3-6 qubits) addressed in the literature so far. . Restricted topology . One of the most remarkable features of this approach is that topology restrictions do not seem to bring any overhead to compilation of random unitaries. To make the point and illustrate this claim I will consider the least connected topology I can think of, the chain topology. The corresponding layer consists of all pairs of adjacent qubits. . def chain_layer(num_qubits): return [(i,i+1) for i in range(num_qubits-1)] . Here is a 6-qubit illustration. . Ansatz(6, &#39;cx&#39;, layer_placements=[chain_layer(6), 1]).circuit().draw(output=&#39;mpl&#39;) . Here I drew a single layer consisting of 5 blocks. To reach the theoretical lower bound requires to stack together 1020/5=204 layers. Let&#39;s do that and see how the learning goes. . %%time num_qubits = 6 depth = TLB(num_qubits) layer_placements, free_placements = fill_layers(chain_layer(num_qubits), depth) u_target = unitary_group.rvs(2**num_qubits, random_state=0) anz = Ansatz(num_qubits, &#39;cx&#39;, layer_placements=layer_placements, free_placements=free_placements) angles_history_chain, loss_history_chain = anz.learn(u_target) . CPU times: user 5min 17s, sys: 1min 3s, total: 6min 21s Wall time: 6min 8s . Let&#39;s compare the results with the previously considered fully connected topology. . plt.title(&#39;number of qubits: {}&#39;.format(num_qubits)) plt.xlabel(&#39;number of iterations&#39;) plt.ylabel(&#39;error&#39;) plt.plot(loss_history, label=&#39;fully connected&#39;) plt.plot(loss_history_chain, label=&#39;chain&#39;) plt.legend() plt.yscale(&#39;log&#39;) . As you can see, the chain topology performs only slightly worse than the fully connected topology which seems truly remarkable. . Final remarks . The main goal was to illustrate that numerical compilation of small-scale random unitaries can be very efficient in terms of gate count, and seems to reach the theoretical lower bound in all cases considered, regardless of topological restrictions. . It is interesting to note that a variety of optimization procedures are used in the literature. In M&amp;S a simple version of the gradient descent is used, in R&amp;Z an interesting procedure of one-qubit gate decoupling is used (I must admit I do not understand exactly what it does), and in KTS preprint a funny optimization one-angle-at a time is used (because as a function of each angle the circuit is a simple triginometric function, it is trivial to optimize one parameter at a time). Here we used a slightly more advanced version of the gradient descent, the Adam algorithm. All approaches seem to work well on random unitaries. . My preliminary investigations show that for special gates things get much more complicated than for generic random unitaries. But this is where the most intersting stuff is found, e.g. compilation of multi-component Toffoli gates on restricted connectivity. I hope to address these cases in a future blog post, or if I&#39;m lucky, in a publication:) .",
            "url": "https://idnm.github.io/blog/blog/qiskit/jax/machine%20learning/compilation/2021/12/09/Machine-learning-compilation-of-quantum-circuits-experiments.html",
            "relUrl": "/qiskit/jax/machine%20learning/compilation/2021/12/09/Machine-learning-compilation-of-quantum-circuits-experiments.html",
            "date": " ‚Ä¢ Dec 9, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Matrix representation of quantum circuits - notations and gotchas",
            "content": "Intro . Usually, for experimenting with quantum circuits I use qiskit. As any higher level environment it is very convenient for common tasks, but may turn out too inflexible for unusual use cases. A somewhat opposite approach is to use much lower level tools to gain in flexibility at the expense of convenience. Currently I want to use Google&#39;s tensornetwork package for simulations and training of quantum circuits, but this requires building many things that are for free in qiskit from scratch. It is also necessary to become explicit about conventions for matrix representation of quantum circuits. As long as you stay within a single framework this may not be an issue. However for debugging purposes as well as for comparison between different frameworks this may become unavoidable. Thus, I always anticipated, that a day will come when I need to face my fears and order all terms in a tensor product by hands. Now it seems I&#39;m past the difficult part and I&#39;m better writing this down in case I would need to do something similar in the future. . Defining the problem . OK, so what is the problem? Consider the following simple circuit built with qiskit: . import numpy as np from qiskit import QuantumCircuit from qiskit.quantum_info import Operator, Statevector qc = QuantumCircuit(2) qc.x(0) qc.y(1) qc.cx(0,1) qc.draw(output=&#39;mpl&#39;) . . It is not hard or ambiguous to interpret what this circuit does by inspecting the diagram. Say the input state is $q_0=|0 rangle$, $q_1=|1 rangle$. After $X$ acts on $q_0$ it becomes $q_0 to X |0 rangle=|1 rangle$. Similarly, $q_1$ after $Y$ becomes $q_1 to Y|1 rangle=-i |0 rangle$. Since now $q_0$ is &quot;on&quot; the CNOT gate switches the state of $q_1$ further to $q_0 to -i|1 rangle$. So the end result is that $q_0=|0 rangle, q_1=|1 rangle$ is transformed to $q_0=|1 rangle, q_1=-i|1 rangle$. Or perhaps a picture says it better . . Similarly, we can work out what the circuit does for other computational basis states which by linearity fully fixes the action of the circuit. Although quite explicit, this is a clumsy description. This is why the matrix notation is usually used. And indeed, we can obtain the matrix corresponding to our quantum circuit quite easily in qiskit: . U_qs = Operator(qc).data U_qs . array([[0.+0.j, 0.+0.j, 0.+0.j, 0.-1.j], [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j, 0.-1.j, 0.+0.j]]) . It is important to realize that a number of conventions must be chosen before such explicit matrix representation can be written down. In particular, I will emphasize two points I tripped over while studying this: ordering of the qubit states in the tensor product or &quot;vertical ordering&quot; and ordering of operators or &quot;horizontal ordering&quot;. . . In the rest of the post I will clarify what are the conventions used in qiskit and how to reproduce the circuit with the tensornetwork library. . States: vertical ordering . Single qubit states . First we need to give matrix representations to two basis states of a single qubit. Here I think it is quite uncontroversial to choose begin{align} |0 rangle = begin{pmatrix}1 0 end{pmatrix}, qquad |1 rangle = begin{pmatrix}0 1 end{pmatrix} label{kets} end{align} . These are the &quot;ket&quot; vectors. Their &quot;bra&quot; counterparts are begin{align} langle 0| = begin{pmatrix}1 &amp; 0 end{pmatrix}, qquad langle 1| = begin{pmatrix}0 &amp; 1 end{pmatrix} label{bras} end{align} . With these, the following operators can be computed begin{align} |0 rangle langle 0| = begin{pmatrix}1 &amp; 0 0 &amp; 0 end{pmatrix}, qquad |0 rangle langle 1| = begin{pmatrix}0 &amp; 1 0 &amp; 0 end{pmatrix} nonumber |1 rangle langle 0| = begin{pmatrix}0 &amp; 0 1 &amp; 0 end{pmatrix}, qquad |1 rangle langle 1| = begin{pmatrix}0 &amp; 0 0 &amp; 1 end{pmatrix} label{ketbras} end{align} . Multiple qubit states . When there is more than a single qubit things become a bit more interesting and potentially confusing. For example, the combined Hilbert space of two qubits $ mathcal{H}_2$ is a tensor product of single-qubit Hilbert spaces $ mathcal{H}_2 = mathcal{H}_1 otimes mathcal{H}_1$ but we need to decide which qubit goes first and which goes second. In qiskit a convention is adopted that additional qubits join from the left, i.e. when we have two qubits as here . qc01 = QuantumCircuit(2) qc01.draw(output=&#39;mpl&#39;) . . The state of the system is $|q_1 rangle otimes |q_0 rangle$ (this is of course only true literally for non-entangled states but we can define everything only on the computational basis states ). OK, but how do we translate this into the matrix representation? The states in the tensor product of vector spaces can be represented by the Kronecker product which is not symmetric with respect to permutation arguments. Best way to explain how Kronecker product works is, as usual, through examples: . begin{align} begin{pmatrix} 1 0 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} a b 0 0 end{pmatrix}, qquad begin{pmatrix} 0 1 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} 0 0 a b end{pmatrix} end{align}Result for generic left vector can be obtained by linearity begin{align} begin{pmatrix} x y end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = x begin{pmatrix} 1 0 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} +y begin{pmatrix} 0 1 end{pmatrix} otimes begin{pmatrix} a b end{pmatrix} = begin{pmatrix} x a x b y a y b end{pmatrix} = begin{pmatrix} x begin{pmatrix} a b end{pmatrix} y begin{pmatrix} a b end{pmatrix} end{pmatrix} end{align} . The last notation here is a bit informal but it shows what happens. One just substitutes the right vector into all elements of the left vector, multiplied by the corresponding components of the left vector. The Kronecker product is defined in the same way for matrices of arbitrary size, not just for two vectors. . So, now we can compute matrix representations of states in the computation basis of two-qubit system . begin{align} |00 rangle = begin{pmatrix}1 0 end{pmatrix} otimes begin{pmatrix}1 0 end{pmatrix} = begin{pmatrix}1 0 0 0 end{pmatrix}, quad |01 rangle = begin{pmatrix}1 0 end{pmatrix} otimes begin{pmatrix}0 1 end{pmatrix} = begin{pmatrix}0 1 0 0 end{pmatrix} label{01} |10 rangle = begin{pmatrix}0 1 end{pmatrix} otimes begin{pmatrix}1 0 end{pmatrix} = begin{pmatrix}0 0 1 0 end{pmatrix}, quad |11 rangle = begin{pmatrix}0 1 end{pmatrix} otimes begin{pmatrix}0 1 end{pmatrix} = begin{pmatrix}0 0 0 1 end{pmatrix} end{align}There is a useful relation between the index of the non-zero element $n$ in the four-dimensional representation and the computational basis bitstring $q_1q_0$, namely $n=2q_1+q_0$. I.e. the bitstring $q_1q_0$ is the binary representation of the index $n$. This extends to arbitrary number of qubits, for example since $101$ is $5$ in binary representation it follows begin{align} |101 rangle = begin{pmatrix}0 0 0 0 0 1 0 0 end{pmatrix} label{101} end{align} (try to obtain this from the two tensor products!) . Don&#39;t believe me? OK, let&#39;s check! In qiskit there is a convenient function to construct a vector representation from a bit string which we will take advantage of. First start with a two-qubit example: . s01 = Statevector.from_label(&#39;01&#39;) s01.data . array([0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]) . Comparing to eqref{01} we find agreement. Similarly, . s101 = Statevector.from_label(&#39;101&#39;) s101.data . array([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]) . Again, this is in agreement with eqref{101}. . However, I am not sure that this relation is sufficient to justify the ordering of the tensor products. To me it is much more natural to read the circuit from top to bottom and construct the Hilbert spaces accordingly, say $ mathcal{H}_0 otimes mathcal{H}_1 otimes mathcal{H}_2 dots$ instead of $ cdots mathcal{H}_2 otimes mathcal{H}_1 otimes mathcal{H}_0$. Later I will change the ordering of the tensor product to my liking, but for now we stick with the qiskit one. Now, with conventions for states in place we can proceed to operators. . Operators: horizontal ordering . One can say that convention for states representation and ordering of tensor products is a &quot;vertical&quot; convention. There is also a &quot;horizontal&quot; convention which might be potentially confusing. Consider the following circuit . qc123 = QuantumCircuit(1) qc123.rx(1, 0) qc123.ry(2, 0) qc123.rz(3, 0) qc123.draw(output=&#39;mpl&#39;) . . Here, the operator $R_x$ is appplied first, the operator $R_y$ second and $R_z$ last. So in mathematical notation the circuit corresponds to $R_z R_y R_x$ and not to $R_x R_y R_z$. I think that the circuit notation is actually better. We think and write from left to right, this is also a direction that time flows on paper. When another thing happens, we write it to the right and it would be convenient to apply the corresponding operator also to the right. I heard real mathematicians complain about that issue, but I guess we are stuck with it for now. . Paper-and-pencil computation . With the set up in place we can compute the circuit of interest by hands. For convenience I plot it here once again: . qc.draw(output=&#39;mpl&#39;) . . OK, so what is the unitary matrix corresponding to this circuit? It is begin{align} U = CNOT_{01} cdot (Y otimes X) end{align} Here begin{multline} CNOT_{01} = mathbb{1} otimes |0 rangle langle 0|+X otimes |1 rangle langle 1|= begin{pmatrix}1&amp;0 0&amp;1 end{pmatrix} otimes begin{pmatrix}1&amp;0 0&amp;0 end{pmatrix}+ begin{pmatrix}0&amp;1 1&amp;0 end{pmatrix} otimes begin{pmatrix}0&amp;0 0&amp;1 end{pmatrix}= begin{pmatrix}1&amp;0&amp;0&amp;0 0&amp;0&amp;0&amp;1 0&amp;0&amp;1&amp;0 0&amp;1&amp;0&amp;0 end{pmatrix} end{multline} and begin{align} Y otimes X = begin{pmatrix} 0&amp; -i i&amp;0 end{pmatrix} otimes begin{pmatrix} 0&amp; 1 1&amp;0 end{pmatrix}= begin{pmatrix}0&amp;0&amp;0&amp;-i 0&amp;0&amp;-i&amp;0 0&amp;i&amp;0&amp;0 i&amp;0&amp;0&amp;0 end{pmatrix} end{align} Multiplying them together gives begin{align} U = begin{pmatrix}0 &amp; 0 &amp; 0 &amp; -i i&amp;0&amp;0&amp;0 0 &amp; i &amp; 0 &amp; 0 0 &amp; 0 &amp; -i &amp; 0 end{pmatrix} end{align} Alright, so this is indeed the matrix that qiskit computes: . U_qs . array([[0.+0.j, 0.+0.j, 0.+0.j, 0.-1.j], [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j, 0.-1.j, 0.+0.j]]) . We can now also check that that the states evolve as we expected. For example recall that we computed that our quantum circuit maps $q_0 =|0 rangle, q_1 =|1 rangle$ to $q_0 =|1 rangle, q_1 =|1 rangle$ with an overall phase $-i$. Agreement with qiskit can be checked as follows: . qs_state = Statevector.from_label(&#39;10&#39;).evolve(qc).data our_state = -1j*Statevector.from_label(&#39;11&#39;).data np.allclose(qs_state, our_state) . True . Implementation with tensornetworks . I will not give a proper introduction to tensor networks but just make some digressions I think should be helpful as we go along. . First thing we will need are the matrices defining $X, Y$ and $CNOT$ gates. Let us introduce them. . X = np.array([[0, 1], [1, 0]]) Y = np.array([[0, -1j], [1j, 0]]) CNOT = np.array([[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0]]).reshape(2,2,2,2) . An aside about reshaping . Note that as usually written, $CNOT$ is a $4 times4$ matrix. Since as a quantum gate it acts on two qubits, so it should rather be a four-legged tensor. This is the purpose of the reshaping operation. At first the reshaping might be a bit tricky, so let me illustrate it with an example. Introduce two $4 times4$ matrices and define their product: . A = np.random.rand(4,4) B = np.random.rand(4,4) AB = A @ B . Now define the corresponding four-legged tensors. . import tensornetwork as tn a = tn.Node(A.reshape(2,2,2,2)) b = tn.Node(B.reshape(2,2,2,2)) . By contracting the legs (or &quot;edges&quot; in terminology of tensornetworks) appropriately, we can reproduce the matrix multiplication. First the code: . a[2] ^ b[0] a[3] ^ b[1] ab = tn.contractors.greedy([a, b], output_edge_order=[a[0], a[1], b[2], b[3]]).tensor . We can check that the contraction performed in this way exactly reproduces the matrix multiplication of original $4 times4$ matrices: . np.allclose(AB, ab.reshape(4,4)) . True . This can be interpreted graphically as follows. First, the reshaping procedure can be thought of as splitting each of two four-dimensional legs of the original matrix into two two-dimensional ones . . The labels on the legs have nothing to do with qubit states, these are just indices of edges as assigned by tn.Node operation on our matrices. The matrix multiplication of the original matrices in terms of four-legged tensors then can be drawn as follows . . The index arrangements in the last part explain why we connected the edges in our code the way we did. This is something to watch out for. For example, connecting edges of two identity tensors in the wrong way may produce a $SWAP$ gate. . Tensor product ordering . The matrix representation of a tensor diagram like this . . also comes with a convention for the ordering of tensor products. In tensornetwork as well as in my opinion it is natural to order top-down, i.e. the above diagram is $U otimes mathbb{1}$ instead of $ mathbb{1} otimes U$ as is adopted in qiskit. . Circuit from tensor network . Alright, not we are in a position to reproduce the circuit unitary from the tensor network with nodes x, y and cnot: . # Make tensors from matrices x, y, cnot = list(map(tn.Node, [X, Y, CNOT])) # Connect edges properly cnot[2] ^ y[0] cnot[3] ^ x[0] # Perform the contraction ~ matrix multiplication U_tn = tn.contractors.greedy([cnot, x, y], output_edge_order=[cnot[0], cnot[1], y[1], x[1]]).tensor . This way of contracting the edges corresponds to the following diagram: . . Note that this is basically the original circuit with both the vertical and the horizontal directions reversed. The horizontal reversal is due to mathematical vs circuit notation (circuit is better!) and the vertical reversal is due to the mismatch between qiskit and tensornetwork ordering of tensor product (tensornetwork&#39;s is better!). We can check that the unitary we obtain from this tensor network agrees with qiskit&#39;s . np.allclose(U_tn.reshape(4,4), U_qs) . True . A better way . I find all this misalignment very inconvenient and hard to debug. Ideally I want to look at the quantum circuit and construct the corresponding tensor network just as I read a text: from left to right and from top to bottom. Here I propose a solution which seems much more satisfactory to me. We will deal with horizontal reversal by first defining edges and then applying gates to them. This way we can read the circuit from left to right and simply add new gates, just as in qiskit. I will not try to revert the vertical direction directly, because I find it hard to think upside down. Instead, for comparison with qiskit I will use a built-in reverse_bits method. . So let&#39;s start by defining a function that applies a given gate to the collection of qubits (this is a slight modification of an example from tensornetwork docs) : . def apply_gate(qubits, gate_tensor, positions): gate = tn.Node(gate_tensor) assert len(gate.edges) == 2*len(positions), &#39;Gate size does not match positions provided.&#39; for i, p in enumerate(positions): # Connect RIGHT legs of the gate to the active qubits gate[i+len(positions)] ^ qubits[p] # Reassing active qubits to the corresponding LEFT legs of the gate qubits[p] = gate[i] . Importantly, here, in contrast to the official docs, we append the gate from the left, so that a sequence of application of some $G_1$ followed by $G_2$ is equivalent to the application of $G_2 cdot G_1$. Now there is one more subtlety. Previously we used matrix representation of $CNOT$ assuming that the uppermost qubit comes last in the tensor product. Now that we decided to turn this convention upside down our matrix representation of $CNOT$ must be $CNOT =|0 rangle langle 0| otimes mathbb{1}+|1 rangle langle 1| otimes X$ or explicitly . CNOT = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]).reshape(2,2,2,2) . With that we are ready to reconstruct our original circuit in a convenient way: . # The context manager `NodeCollection` is a bit of a magic trick # which keeps track of all tensors in the network automatically. all_nodes = [] with tn.NodeCollection(all_nodes): # I do not know how to create &#39;abstract&#39; edges in `tensornetworks`. # Instead, I create an identity tensor and use its edges to apply new gates to. id0 = tn.Node(np.identity(4).reshape(2,2,2,2)) qubits0 = id0.edges[2:4] qubits = id0.edges[0:2] apply_gate(qubits, X, [0]) apply_gate(qubits, Y, [1]) apply_gate(qubits, CNOT, [0,1]) . Now let us check! . U_tn = tn.contractors.greedy(all_nodes, output_edge_order=qubits+qubits0).tensor.reshape(4,4) U_reversed_qs = Operator(qc.reverse_bits()).data np.allclose(U_tn, U_reversed_qs) . True . Wohoo, it worked! If that looked simple to you I&#39;m happy. It took me several hours of debugging to finally match the two matrices. Just to make sure, let me conclude with a more complicated example. . qc3 = QuantumCircuit(3) qc3.x(0) qc3.cx(0, 1) qc3.y(1) qc3.x(2) qc3.cx(2, 1) qc3.y(2) qc3.draw(output=&#39;mpl&#39;) . As you can see, constructing the tensor network analog now works more or less identically: . all_nodes = [] with tn.NodeCollection(all_nodes): id0 = tn.Node(np.identity(8).reshape(2,2,2,2,2,2)) qubits0 = id0.edges[3:6] qubits = id0.edges[0:3] # The essential part apply_gate(qubits, X, [0]) apply_gate(qubits, CNOT, [0, 1]) apply_gate(qubits, Y, [1]) apply_gate(qubits, X, [2]) apply_gate(qubits, CNOT, [2, 1]) apply_gate(qubits, Y, [2]) . And now we compare: . U3_tn = tn.contractors.greedy(all_nodes, output_edge_order=qubits+qubits0).tensor.reshape(8,8) U3_qs_reversed = Operator(qc3.reverse_bits()).data np.allclose(U3_tn, U3_qs_reversed) . True . Alright, this resounding True is the best way to conclude that comes to mind. I own many thanks to Ilia Luchnikov for the help with tensornetwork library. Any questions are welcome in the comments! .",
            "url": "https://idnm.github.io/blog/blog/qiskit/tensor%20networks/quantum%20concepts/2021/08/18/Matrix-representation-of-quantum-circuits.html",
            "relUrl": "/qiskit/tensor%20networks/quantum%20concepts/2021/08/18/Matrix-representation-of-quantum-circuits.html",
            "date": " ‚Ä¢ Aug 18, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Machine learning compilation of quantum circuits",
            "content": "Introduction . I am going to review a recent preprint by Liam Madden and Andrea Simonetto that uses techniques from machine learning to tackle the problem of quantum circuits compilation. I find the approach suggested in the paper very interesting and the preliminary results quite promising. . What is compilation? . Note that a variety of terms are floating around the literature and used more or less interchangibly. Among those are synthesis, compilation, transpilation and decomposition of quantum circuits. I will not make a distinction and try to stick to compilation. . But first things first, what is a compilation of a quantum circuit? The best motivation and illustration for the problem is the following. Say you need to run a textbook quantum circuit on a real hardware. The real hardware usually allows only for a few basic one and two qubit gates. In contrast, your typical textbook quantum circuit may feature (1) complex many-qubit gates, for example multi-controlled gates and (2) one and two qubit gates which are not supported by the hardware. As a simple example take this 3-qubit Grover&#39;s circuit (from qiskit textbook): . #initialization import matplotlib.pyplot as plt import numpy as np # importing Qiskit from qiskit import IBMQ, Aer, assemble, transpile from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister from qiskit.providers.ibmq import least_busy # import basic plot tools from qiskit.visualization import plot_histogram def initialize_s(qc, qubits): &quot;&quot;&quot;Apply a H-gate to &#39;qubits&#39; in qc&quot;&quot;&quot; for q in qubits: qc.h(q) return qc def diffuser(nqubits): qc = QuantumCircuit(nqubits) # Apply transformation |s&gt; -&gt; |00..0&gt; (H-gates) for qubit in range(nqubits): qc.h(qubit) # Apply transformation |00..0&gt; -&gt; |11..1&gt; (X-gates) for qubit in range(nqubits): qc.x(qubit) # Do multi-controlled-Z gate qc.h(nqubits-1) qc.mct(list(range(nqubits-1)), nqubits-1) # multi-controlled-toffoli qc.h(nqubits-1) # Apply transformation |11..1&gt; -&gt; |00..0&gt; for qubit in range(nqubits): qc.x(qubit) # Apply transformation |00..0&gt; -&gt; |s&gt; for qubit in range(nqubits): qc.h(qubit) # We will return the diffuser as a gate U_s = qc.to_gate() U_s.name = &quot;U$_s$&quot; return U_s qc = QuantumCircuit(3) qc.cz(0, 2) qc.cz(1, 2) oracle_ex3 = qc.to_gate() oracle_ex3.name = &quot;U$_ omega$&quot; n = 3 grover_circuit = QuantumCircuit(n) grover_circuit = initialize_s(grover_circuit, [0,1,2]) grover_circuit.append(oracle_ex3, [0,1,2]) grover_circuit.append(diffuser(n), [0,1,2]) grover_circuit = grover_circuit.decompose() grover_circuit.draw(output=&#39;mpl&#39;) . . The three qubit gates like Toffoli are not generally available on a hardware and one and two qubit gates my be different from those in the textbook algorithm. For example ion quantum computers are good with M√∏lmer‚ÄìS√∏rensen gates and may need several native one qubit gates to implement the Hadamard gate. . Additional important problem is to take into account qubit connectivity. Usually textbook algorithms assume full connectivity, meaning that two-qubit gates can act on any pair of qubits. On most hardware platforms however a qubit can only interact with its neighbors. Assuming that one and two qubits gates available on the hardware can implement a SWAP gate between adjacent qubits, to solve the connectivity problem one can insert as many SWAPs as necessary to connect topologically disjoint qubits. Using SWAPs however leads to a huge overhead in the number of total gates in the compiled circuit, and it is of much importance use them as economically as possible. In fact, the problem of optimal SWAPping alone in generic situation is NP-complete. . Simplified problem . When compiling a quantum circuit one has to decide which resulting circuits are considered to be efficient. Ideally, one should optimize for the total fidelity of the circuit. Let us imagine running the algorithm on a real device. Probably my theorist&#39;s image of a real device is still way too platonic, but I will try my best. Many details need to be taken into account. For example, gates acting on different qubits or pairs of qubits may have different fidelities. Decoherence of qubits with time can make circuits where many operations can be executed in parallel more favorable. Cross-talk (unwanted interactions) between neighboring qubits may lead to exotic patterns for optimal circuits. A simple proxy for the resulting fidelity that is often adopted is the number of two-qubit gates (which are generically much less accurate than a single-qubit gates). So the problem that is often studied, and that is addressed in the preprint we are going to discuss, is the problem of optimal compilation into a gate set consisting of arbitrary single-qubit gates and CNOTs, the only two qubits gate. The compiled circuit must . Respect hardware connectivity. | Have as few CNOTs as possible. | Exceed a given fidelity threshold. | Last item here means that we also allow for an approximate compilation. By increasing the number of CNOTs one can always achieve an exact compilation, but since in reality each additional CNOT comes with its own fidelity cost this might not be a good trade-off. Note also that a specific choice for two-qubit gate is made, a CNOT gate. Any two-qubit gate can be decomposed into at most 3 CNOTs see e.g. here, so in terms of computational complexity this is of course inconsequential. However in the following discussion we will care a lot about constant factors and may wish to revisit this choice at the end. . Existing results . Since finding the exact optimal solution to the compilation problem is intractable, as with many things in life one needs to resort to heuristic methods. A combination of many heuristic methods, in fact. As an example one can check out the transpilation workflow in qiskit. Among others, there is a step that compiles &gt;2 qubit gates into one and two qubit gates; the one that tries to find a good initial placement of the logical qubits onto physical hardware; the one that &#39;routes&#39; the desired circuit to match a given topology being as greedy on SWAPs as possible. Each of these steps can use several different heuristic optimization algorithms, which are continuously refined and extended (for example this recent preprint improves on the default rounting procedure in qiskit). In my opinion it would be waay better to have one unified heuristic for all steps of the process, especially taking into account that they are not completely independent. Although this might be too much to ask for, some advances are definitely possible and machine learning tools might prove very useful. The paper we are going to discuss is an excellent demonstration. . Theoretical lower bound and quantum Shannon decomposition . There is a couple of very nice theoretical results about the compilation problem that I need to mention. But first, let us agree that we will compile unitaries, not circuits. What is the difference? Of course, any quantum circuit (without measurements and neglecting losses) corresponds to a unitary matrix. However, to compute that unitary matrix for a large quantum circuit explicitly is generally an intractable problem, precisely for the same reasons that quantum computation is assumed to be more powerful than classical. Still, taking as the input a unitary matrix (which is in general hard to compute from the circuit) is very useful both theoretically and practically. I will discuss pros and cons of this approach later on. . OK, now the fun fact. Generically, one needs at least this many CNOTs . begin{align} L:= # text{CNOTs} geq frac14 left(4^n-3n-1 right) label{TLB} end{align}to exactly compile an $n$-qubit unitary. &#39;Generically&#39; means that the set of $n$-qubit unitaries that can be compiled exactly with smaller amount of CNOTs has measure zero. Keep in mind though, that there are important unitaries in this class like multi-controlled gates or qubit permutations. We will discuss compilation of some gates from the &#39;measure-zero&#39; later on. . The authors of the preprint (I hope you and me still remember that there is some actual results to discuss, not just my overly long introduction to read) refer to eqref{TLB} as the theoretical lower bound or TLB for short. The proof of this fact is actually rather simple and I will sketch it. A general $d times d$ unitary has $d^2$ real parameters. For $n$ qubits $d=2^n$. Single one-qubit gate has 3 real parameters. Any sequence of one-qubit gates applied to the same qubit can be reduced to a single one-qubit gate and hence can have no more than 3 parameters. That means, that without CNOTs we can only have 3n parameters in our circuit, 3 for each one-qubit gate. This is definitely not enough to describe an arbitrary unitary on $n$ qubits which has $d^2=4^n$ parameters. . Now, adding a single CNOT allows to insert two more 1-qubit unitaries after it, like that . from qiskit.circuit import Parameter a1, a2, a3 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;, &#39;a3&#39;]] b1, b2, b3 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;, &#39;b3&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.u(a1, a2, a3, 0) qc.u(b1, b2, b3, 1) qc.draw(output=&#39;mpl&#39;) . . At the first glance this allows to add 6 more parameters. However, each single-qubit unitary can be represented via the Euler angles as a product of only $R_z$ and $R_x$ rotations either as $U=R_z R_x R_z$ or $U=R_x R_y R_z$ (I do not specify angles). Now, CNOT can be represented as $CNOT=|0 rangle langle 0| otimes I+|1 rangle langle 1| otimes X$. It follows that $R_z$ commutes with the control of CNOT and $R_x$ commutes with the target of CNOT, hence they can be dragged to the left and joined with preceding one-qubit gates. So in fact each new CNOT gate allows to add only 4 real parameters: . a1, a2 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;]] b1, b2 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.rx(a1, 0) qc.rz(a2, 0) qc.rz(b1, 1) qc.rx(b2, 1) qc.draw(output=&#39;mpl&#39;) . . That&#39;s it, there are no more caveats. Thus, the total number of parameters we can get with $L$ CNOTs is $3n+4L$ and we need to describe a $d times d$ unitary which has $4^n$ parameters. In fact, the global phase of the unitary is irrelevant so we only need $3n+4L geq 4^n-1$. Solving for $L$ gives the TLB eqref{TLB}. That&#39;s pretty cool, isn&#39;t it? . Now there is an algorithm, called quantum Shannon decomposition (see ref), which gives an exact compilation of any unitary with the number of CNOTs twice as much as the TLB requires. In complexity-theoretic terms an overall factor of two is of course inessential, but for current NISQ devices we want to get as efficient as possible. Moreover, to my understanding the quantum Shannon decomposition is not easily extendable to restricted topology while inefficient generalizations lead to a much bigger overhead (roughly an order of magnitude). . What&#39;s in the preprint? . Templates . I&#39;ve already wrote an introduction way longer than intended so from now on I will try to be brief and to the point. The authors of the preprint propose two templates inspired by the quantum Shannon decomposition. The building block for each template is a &#39;CNOT unit&#39; . a1, a2 = [Parameter(a) for a in [&#39;a1&#39;, &#39;a2&#39;]] b1, b2 = [Parameter(b) for b in [&#39;b1&#39;, &#39;b2&#39;]] qc = QuantumCircuit(2) qc.cx(0, 1) qc.ry(a1, 0) qc.rz(a2, 0) qc.ry(b1, 1) qc.rx(b2, 1) qc.draw(output=&#39;mpl&#39;) . . First template is called sequ in the paper and is obtained as follows. There are $n(n-1)/2$ different CNOTs on $n$-qubit gates. We enumerate them somehow and simply stack sequentially. Here is a 3-qubut example with two layers (I use qiskit gates cz instead of our &#39;CNOT units&#39; for the ease of graphical representation) . qc = QuantumCircuit(3) for _ in range(2): qc.cz(0, 1) qc.cz(0, 2) qc.cz(1, 2) qc.barrier() qc.draw(output=&#39;mpl&#39;) . . The second template is called spin and for 4 qubits looks as follows . qc = QuantumCircuit(4) for _ in range(2): qc.cz(0, 1) qc.cz(1, 2) qc.cz(2, 3) qc.barrier() qc.draw(output=&#39;mpl&#39;) . . I&#39;m sure you get the idea. That&#39;s it! The templates fix the pattern of CNOTs while angles of single-qubit gates are adjustable parameters which are collectively denoted by $ theta$. . The idea now is simple. Try to optimize these parameters to achieve the highest possible fidelity for a given target unitary to compile. I am not at all an expert on the optimization methods, so I might miss many subtleties, but on the surface the problem looks rather straightforward. You can choose your favorite flavor of the gradient descent and hope for convergence. The problem appears to be non-convex but the gradient descent seems to work well in practice. One technical point that I do not fully understand is that the authors choose to work with fidelity defined by the Frobenius norm $||U-V||_F^2$ which is sensitive to the global phase of each unitary. To my understanding they often find that local minima of this fidelity coincides with the global minimum up to a global phase. OK, so in the rest of the post I refer to the &#39;gradient descent&#39; as the magic numerical method which does good job of finding physically sound minimums. . Results . Compiling random unitaries . OK, finally, for the surprising results. The authors find experimentally that both sequ and spin perform surprisingly well on random unitaries always coming very close to the TLB eqref{TLB} with good fidelity. More precisely, the tests proceed as follows. First, one generates a random unitary. Next, for each number $L$ of CNOTs below the TLB one runs the gradient descent to see how much fidelity can be achieved with this amount of CNOTs. Finally, one plots the fidelity as a function of $L$. Impressively, on the sample of hundred unitaries the fidelity always approaches 100% when the number of CNOTs reaches the TLB. For the $n=3$ qubits TLB is $L=14$, for $n=5$ $L=252$ (these are the two cases studied). So, in all cases studied, the gradient descent lead by the provided templates seems to always find the optimal compilation circuit! Recall that this is two times better than quantum Shannon decomposition. Please see the original paper for nice plots that I do not reproduce here. . Compiling on restricted topology . These tests were performed on the fully connected circuits. The next remarkable discovery is that restricting the connectivity does not to seem to harm the performance of the compilation! More precisely, the authors considered two restricted topologies in the paper, &#39;star&#39; where all qubits are connected to single central one and &#39;line&#39; where well, they are connected by links on a line. The spin template can not be applied to star topology, but it can be applied to line topology. The sequ template can be generalized to any topology by simply omitting CNOTs that are not allowed. Again, as examining a hundred of random unitaries on $n=3$ and $n=5$ qubits shows, the fidelity nearing 100% can be achieved right at the TLB in all cases, which hints that topology restriction may not be a problem in this approach at all! To appreciate the achievement, imagine decomposing each unitary via the quantum Shannon decomposition and then routing on restricted topology with swarms of SWAPs, a terrifying picture indeed. It would be interesting to compare the results against the performance of qiskit transpiler which is unfortunately not done in the paper to my understanding. . Compiling specific &#39;measure zero&#39; gates . Some important multi-qubit gates fall into the &#39;measure zero&#39; set which can be compiled with a smaller amount of CNOTs than is implied by the TLB eqref{TLB}. For example, 4-qubit Toffoli gate can be compiled with 14 CNOTs while the TLB requires 61 gates. Numerical tests show that the plain version of the algorithm presented above does not generically obtain the optimal compilation for special gates. However, with some tweaking and increasing the amount of attempts the authors were able to find optimal decompositions for a number of known gates such as 3- and 4-qubit Toffoli, 3-qubit Fredkin and 1-bit full adder on 4 qubits. The tweaking included randomly changing the orientation of some CNOTs (note that in both sequ and spin the control qubit is always at the top) and running many optimization cycles with random initial conditions. The best performing method appeared to be sequ with random flips of CNOTs. The whole strategy might look a bit fishy, but I would argue that it is not. My argument is simple: you only need to find a good compilation of the 4-qubit Toffoli once. After that you pat yourself on the back and use the result in all your algorithms. So it does not really matter how hard it was to find the compilation as long as you did not forget to write it down. . Compressing the quantum Shannon decomposition . Finally, as a new twist on the plot the authors propose a method to compress the standard quantum Shannon decomposition (which is twice the TLB, remember?). The idea seems simple and works surprisingly well. The algorithm works as follows. . Compile a unitary exactly using the quantum Shannon decomposition. | Promote parameters in single-qubit gates variables (they have fixed values in quantum Shannon decomposition). | Add LASSO-type regularization term, which forces one-qubit gates to have small parameters, ideally zero (which makes the corresponding gates into identities). | Run a gradient descent on the regularized cost function (fidelity+LASSO term). Some one-qubit gates will become identity after that (one might need to tune the regularization parameter here). | After eliminating identity one-qubit gates one can end up in the situation where there is a bunch of CNOTs with no single-qubit gates in between. There are efficient algorithms for reducing the amount of CNOTs in this case. | Recall that the fidelity was compromised by adding regularization terms. Run the gradient descent once more, this time without regularization, to squeeze out these last percents of fidelity. | From the description of this algorithm it does not appear obvious that the required cancellations (elimination of single-qubit gates and cancellations in resulting CNOT clusters) is bound to happen, but the experimental tests show that they do. Again, from a bunch of random unitaries it seems that the $ times 2$ reduction to the TLB is almost sure to happen! Please see the preprint for plots. . Weak spots . Although I find results of the paper largely impressive, a couple of weak spots deserve a mention. . Limited scope of experiments . The numerical experiments were only carried out for $n=3$ and $n=5$ qubits which of course is not much. To see if the method keeps working as the number of qubits is scaled is sure very important. There may be two promblems. First, the templates can fail to be expressive enough for larger circuits. The authors hope to attack this problem from the theoretical side and show that the templates do fill the space of unitaries. Well, best of luck with that! Another potential problem is that although the templates work fine for higher $n$, the learning part might become way more challenging. Well, I guess we should wait and see. . Unitary as the input . As I discussed somewhere way above, for a realistic quantum computation we can not know the unitary matrix that we need to compile. If we did, there would no need in the quantum computer in the first place. I can make two objects here. First, we are still in the NISQ era and pushing the existing quantum computers to their edge is a very important task. Even if an algorithm can be simulated classically, running it on a real device might be invaluable. Second, even quantum circuits on 1000 qubits do not usually feature 100-qubit unitaries. So it could be possible to separate a realistic quantum circuit into pieces, each containing only a few qubits, and compile them separately. . Final remarks . To me, the algorithms presented in the preprint seem to be refreshingly efficient and universal. At some level it appears to be irrelevant which exact template do we use. Near the theoretical lower bound they all perform similarly well, even on restricted topology. This might be a justification for choosing CNOT as the two-qubit gate, as this probably does not matter in the end! I&#39;m really cheering for a universal algorithm like that to win the compilation challenge over a complicated web of isolated heuristics, which are currently state of the art. .",
            "url": "https://idnm.github.io/blog/blog/machine%20learning/compilation/qiskit/paper%20review/2021/07/22/Machine-learning-compilation-of-quantum-circuits.html",
            "relUrl": "/machine%20learning/compilation/qiskit/paper%20review/2021/07/22/Machine-learning-compilation-of-quantum-circuits.html",
            "date": " ‚Ä¢ Jul 22, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "What is entanglement?",
            "content": "Introduction . I&#39;ve known the formal definition of entanglement for years, but I am only now appreciating many of its profound implications. In this post I would like to share two aspects that put entangled states into sharp contrast with unentangled (separable pure) states and classical random variables. Instead of proofs I provide references and simple experiments in qiskit. . . Entanglement is the failure of states to factorize . So what is entanglement? Entanglement is what entangled states have. What are those? Take two spins. The state . begin{equation} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) label{bell} end{equation}is your canonical example of an entangled stated. In contrast, all the states below are unentangled begin{align} | uparrow uparrow rangle, qquad | downarrow uparrow rangle, qquad frac1{ sqrt{2}}| uparrow rangle Big(| uparrow rangle-| downarrow rangle Big), qquad frac1{ sqrt{2}} Big(| uparrow rangle-| downarrow rangle Big) Big(| uparrow rangle+| downarrow rangle Big) label{unen} end{align} . The difference between eqref{bell} and eqref{unen} is the following. All latter states are actually products of the form $| psi_1 rangle | psi_2 rangle$ where $| psi_1 rangle$ is the state of the first system and $| psi_2 rangle$ of the second. In contrast, state eqref{bell} can not be represented in as a product. It is instead a linear combination of factorized states which is not reducible to a single product. You can define entangled states by this property of not being factorizible into states of consistuent spins. . Now that we know what entangled states are it is perfectly reasonable to ask: &quot;so what?&quot;. Why are entangled states special? I am going to give two angles on this questions, out of many possible. . . Note for the sake of concreteness and simplicity I talk about &quot;spins&quot;. In the context of discrete-variable quantum computation &quot;spin&quot;$ equiv$&quot;qubit&quot;, but I prefer spins, because they come with a useful geometrical intuition. The abstract Bloch sphere associated to a qubit describes an actual orientation of a spin in $3d$ space. . Entangled spin behaves very differently from unentangled . A spin which is not entangled can always be described by a direction $ bf n$ along which it is pointing $| uparrow_{ bf n} rangle$. If one measures the component of the spin along this direction, the result is always $ frac12$. Such a measurement corresponds to a projector $P({ bf n})={ bf n} cdot { bf sigma}=n_x sigma_x+n_y sigma_y+n_z sigma_z$. If state $| uparrow_{ bf n} rangle$ is measured along a different axis $ bf n&#39;$ the result depends on the angle $ theta$ between $ bf n$ and $ bf n&#39;$. With probability $ cos^2 frac theta2$ one gets projection $+ frac12$ and with probability $ sin^2 frac theta2$ one gets $- frac12$. However, for any state of the spin $| psi rangle$ there is an axis $ bf n$, such that measuring the spin along this axis gives $ frac12$ with probability one. . This is also true for any of the unentangled states eqref{unen}. For example, measuring the projection of the first spin in the state $| uparrow uparrow rangle equiv | uparrow_{ bf z} uparrow_{ bf z} rangle$ along $ bf z$ always gives $+ frac12$. As another example, since begin{align} | downarrow_{ bf x} rangle= frac12 Big(| uparrow_{ bf z} rangle-| downarrow_{ bf z} rangle Big) label{xdown} end{align} the state $ frac1{ sqrt{2}} Big(| uparrow rangle-| downarrow rangle Big) Big( uparrow rangle+| downarrow rangle Big)$ always registers $- frac12$ when the projection of the first spin along $ bf x$ axis is measured. . In contrast, for the maximally entangled state eqref{bell} the axis with a definite projection of the first spin does not exist. In fact, for all intents and purposes, if you only look at observables associated with the first qubit, state eqref{bell} behaves as a statistical ensemble of states $| uparrow rangle$ and $| downarrow rangle$, i.e. . begin{align} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) approx cases{| uparrow rangle text{ with probability $ frac12$} | downarrow rangle text{ with probability $ frac12$}} label{bellapprox} end{align}This means, for example, that projection onto $ bf z$ axis of the first spin is completely random: with probability $ frac12$ it behaves as $| uparrow rangle$ and gives projection $+ frac12$, with probability $ frac12$ it behaves as $| downarrow rangle$ and gives projection $- frac12$. This is different from a coherent superposition of the up and down states, such as eqref{xdown}. Although state eqref{xdown} gives random results when measured along $ bf z$, it gives certain results when measured along $ bf x$. There is no such axis for state eqref{bellapprox}. In fact, the spin projection along any axis is completely random. . To prove this fact I would need to go into some details of how one does construct an ensemble from an entangled state. This is not at all difficult but I won&#39;t do it here. I encourage an interested reader to consult John Preskill&#39;s notes (chapter 2.3). . Instead, let me do a quick experimental check using qiskit. A Hadamard gate followed by a CNOT creates our state eqref{bell}: . from qiskit import QuantumCircuit, BasicAer, execute from qiskit.visualization import plot_histogram qc = QuantumCircuit(2, 1) qc.h(0) qc.cx(0, 1) qc.draw(output=&#39;mpl&#39;) . To my knowledge, one can only measure in the computational basis in qiskit, i.e. only along $ bf z$ axis in our terminology. To measure a spin along some axis $ bf n$ we can instead rotate the spin itself, and then measure along $ bf z$ axis. Mathematically, if ${ bf n} = R^{-1} { bf z}$ for some rotation $R$ then $ langle uparrow_{ bf z}|P({ bf n})| uparrow_ rangle= langle uparrow_{R{ bf z}}|P({ bf z})| uparrow_{R{ bf z}} rangle$. . # Feel free to change them and see if the outcome distribution changes. theta, pi, lam = 0.13, 0.89, 0.37 qc.u(theta, pi, lam, 0) # Rotate the qubit. qc.measure(0, 0) # Execute on a simulator and plot a histogram of the result. backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=1000).result() counts = result.get_counts(qc) plot_histogram(counts) . The result looks like a fair sample from the uniform probability distribution. This means that projection on the axis we have specified is indeed random. You can try to change the axis and see if you can get a biased distribution (spoiler: you can not). . Entanglement correlations are stronger than classical . First let me note that although we talked about the first spin before, the state eqref{bell} is symmetric and everything equally applies to the second spin. Although the behavior of each of these spins is completely random, there are strong correlations between the them. If we can make local measurements on both spins the state eqref{bell} behaves as . begin{align} frac1{ sqrt{2}} Big(| uparrow uparrow rangle+| downarrow downarrow rangle Big) approx cases{| uparrow uparrow rangle text{ with probability $ frac12$} | downarrow downarrow rangle text{ with probability $ frac12$}} label{bellapprox2} end{align}So for example projections onto $ bf z$ axis of both spins are always the same, although random. Again, this in fact holds for any axis. Here is an experimental verification. . qc = QuantumCircuit(2, 2) qc.h(0) qc.cx(0, 1) # Rotation of each qubit to simulate measurement along arbitary axis. theta, pi, lam = 0.13, 0.89, 0.37 qc.u(theta, pi, lam, 0) qc.u(theta, pi, lam, 1) qc.measure([0, 1], [0, 1]) # Simulate and plot results. backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=2000).result() counts = result.get_counts(qc) plot_histogram(counts) . The result I get is almost certainly a uniform distribution of over $00=| uparrow_{ bf n} uparrow_{ bf n} rangle$ and $11=| downarrow_{ bf n} downarrow_{ bf n} rangle$ (you can change $ bf n$ by changing angles in the code), however I also get a tiny number of spurious counts for $01$ and $10$, which is probably a bug, hm. . When seeing this for the first time there is definitely something to contemplate, like say an EPR paradox. Spoiler: it is not possible to use these correlations for superluminal transmission of information, but they are still a valuable resource. I will discuss just one manifestation of these quantum correlations which has a very concrete operational interpretation -- it allows a quantum team to play a certain probabilistic game better than any classical team could! Note that this is also basically Bell&#39;s theorem in disguise. . So here is the setup. Alice and Bob are playing together against Charlie. Charlie sends random uncorrelated bits $x$ to Alice and $y$ to Bob. Admittedly, Charlie&#39;s job is not very creative and nothing in his strategy can be changed. Now, in response to the obtained bits Alice produces her output bit $a$ and Bob his $b$. Team A&amp;B wins if $a oplus b=x land y$ where $ oplus$ is XOR (sum modulo 2) and $ land$ is the logical AND. Explicitly, if $x land y=1$ both Alice and Bob got $x=y=1$ (which happens one quarter of the time) and they win iff they respond $a=0, b=1$ or $a=1, b=0$ so that $a oplus b=1$. For all other inputs from Charlie, i.e. when $(x,y)$ is equal to $(0,0), (1,0)$ or $(0,1)$ the logical sum $x land y=0$ and Alice and Bob win iff $a=0,b=0$ or $a=1, b=1$ so that $a oplus b=0$. . Now, although in the same team, Alice and Bob are not allowed to communicate during the game. But they can discuss their strategy in advance. The best that a classical team can do is to win $75 %$ of the time. To achieve this winning rate it is sufficient to simply output $a=0, b=0$ irrespective of Charlie&#39;s bits $x,y$. This strategy only loses when $x=y=1$, i.e. one quarter of the time. . Now comes the interesting part. If Alice and Bob each have a spin, and these spins are entangled as in state eqref{bell}, they can achieve the winning probability begin{align} P_{win}= frac12+ frac1{2 sqrt{2}} approx 0.85! label{pwin} end{align} So, what should they do? . Define four axes $ bf n_1,n_2,n_3,n_4$ in the $ bf xz$ plane (of course this is just one of the possibilities). Take ${ bf n_1}= (1,0)$, then ${ bf n_2}=( frac1{ sqrt{2}}, frac1{ sqrt{2}})$ is counter-clockwise rotated by $ pi/4$ wrt to $ bf n_1$; ${ bf n_3}=(0,1)$ is rotated by $ pi/2$; and finally ${ bf n_4}=(- frac1{ sqrt{2}}, frac1{ sqrt{2}})$ is rotated by $3 pi/4$. . . Now here is the strategy that Alice and Bob follow begin{align} a(x)= cases{P_{ bf n_3}, qquad x=0 P_{ bf n_1}, qquad x=1} qquad qquad b(y)= cases{P_{ bf n_2}, qquad y=0 P_{ bf n_4}, qquad y=1} label{abcases} end{align} . Where $P_{ bf n}=+1$ if Alice&#39;s (or Bob&#39;s) spin gave projection $+ frac12$ when measured along $ bf n$ and $P_{ bf n}=0$ if the projection was $- frac12$. An example: if Alice recieves $x=0$ and Bob $y=1$ Alice measures her spin along $n_3= bf z$ axis and sends back the result, while Bob measures his spin along $ bf{n_4}$ (which is $3 pi/4$ rotated $ bf x$ axis) and sends his result. . Now, shall we check that this strategy indeed achieves the advertised winning probability eqref{pwin}? Sure, I also thought so! . import numpy as np # Define rotation axes by their angles. theta1 = 0 theta2 = np.pi/4 theta3 = np.pi/2 theta4 = 3*np.pi/4 def charlie(): # Charlies job is to generate two random bits. return np.random.randint(0,1+1, size=(2)) def alice(x): # Alice decides on the measurement axis according to her strategy. if x==0: return theta3 if x==1: return theta1 def bob(x): # Bob does his part of the protocol. if x==0: return theta2 if x==1: return theta4 def one_round(): # First we prepare an entangled state. qc = QuantumCircuit(2, 2) qc.h(0) qc.cx(0, 1) # Now Charlie generates his bits. x, y = charlie() # A&amp;B team makes their move. a_angle = alice(x) b_angle = bob(y) # Again, we can not measure directly along the desired axes, # but must rotate the qubits instead. Rotation in the xz plane is made by `ry` gate. qc.ry(a_angle, 0) # Alice rotates her qubit. qc.ry(b_angle, 1) # Bob his. # Now we add measurments and actually run the circuit. qc.measure([0, 1], [0, 1]) backend = BasicAer.get_backend(&#39;qasm_simulator&#39;) result = execute(qc, backend, shots=1).result() counts = result.get_counts(qc) # Output of counts is a dict like `{&#39;01&#39;: 1}`. This extracts the measurment results: a, b = [int(c) for c in list(counts.keys())[0]] # And now we check, team A&amp;B gogogo! return (a + b) % 2 == x * y . Alright, now let us collect the statistics: num_rounds = 2000 wins = 0 for _ in range(num_rounds): wins += one_round() print (&quot;Win probability:{}&quot;.format(wins/num_rounds)) . Win probability:0.847 . So that&#39;s pretty close to the theoretical value eqref{pwin}. Note that for each round of the game a new entangled pair is needed. . Now that we have seen that the strategy works let us briefly discuss why. I will only give a sketch and refer for details to Preskill&#39;s lectures chap 4.3. . One thing Alice and Bob could do is to always measure along the same axes. Then, their results would be perfectly correlated (i.e. they always output $a=b=0$ or $a=b=1$) which gives 0.75 winning probability, the same as the best deterministic strategy. Now, in one quarter of cases (when $x=y=1$) they are better off outputting anticorrelated results. If we revisit the figure above equation eqref{abcases} we see that the angle between $a(1)$ and $b(1)$ is $3 pi/4$ which indeed gives a negative correlation in this case $ Big( cos frac{3 pi}{4}=- frac{1}{ sqrt{2}} Big)$. The price to pay is that angles between $ Big(a(0),b(0) Big)$, $ Big(a(0),b(1) Big)$ and $ Big(a(1),b(0) Big)$ are now non-zero (and hence correlations are less than 1) which makes this strategy lose in some cases when the deterministic strategy wins. However, as we have seen experimentally the trade-off is still in our favor. It is also possible to prove that our choice of axes gives the maximum possible win probability. This is ultimately bound by Tsirelson&#39;s bound, see below. . Now you might ask -- what if there exists a clever randomized classical strategy which would perform better than deterministic 0.75 using a similar trick? Turns out this is not possible. The proof is based on the following inequality begin{align} Big| langle a_0 b_0 rangle+ langle a_0 b_1 rangle+ langle a_1 b_0 rangle- langle a_1 b_1 rangle Big| leq 2 end{align} which holds for any random variables $a_0, a_1, b_0, b_1$ taking values $ pm1$ and described by a joint probability distribution. This is known as CHSH inequality and a technical proof is trivial. Why quantum correlations do not have to obey the bound? Well, the reason is somewhat deep and quantum and ultimately related to Bohr&#39;s complementarity) -- non-commuting observables can not be simultaneously assigned values. That this statement has quantitative consequences is illustrated by Bell&#39;s theorem or our game. . Tehcnically quantum correlations obey the Tsirelson&#39;s bound begin{align} Big| langle a_0 b_0 rangle+ langle a_0 b_1 rangle+ langle a_1 b_0 rangle- langle a_1 b_1 rangle Big| leq 2 sqrt{2} end{align} which, as you see, is weaker by a factor $ sqrt{2}$, so the correlations themselves can be stronger, although still bounded. . Final remarks . Quantum entanglement is indeed very unusual and consequential. There are many more wonders that it entails, please consult your favorite lecture notes for a non-exhaustive list. My current favorite are John Preskill&#39;s lecture notes. For a non-mathematical although technically very accurate discussion of entanglement see this artice by Frank Wilczek entanglement made simple. . Any questions and suggestions are welcome, as this is my first blog demo. .",
            "url": "https://idnm.github.io/blog/blog/quantum%20concepts/qiskit/2021/07/12/Entanglement.html",
            "relUrl": "/quantum%20concepts/qiskit/2021/07/12/Entanglement.html",
            "date": " ‚Ä¢ Jul 12, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "How was this blog set up?",
            "content": "Why fastpages? . After deciding to start a scientific blog I was looking for an appropriate technical solution. My main requirements were . Ease of set up. | Ease of writing posts. | Decent support of $ LaTeX$. | Support of code snippets. | . After some search I decided to try out fastpages. I have a very limited understanding of the stack that fastpages use, so I treat it as a magic box. The magic box was easy for me to install while other bullet points are addressed all at once since fastpages allows to generate a post from a jupyter notebook. Although jupyter notebook is not exactly my favorite $ LaTeX$ editor it still much better than many other options and a good overall compromise. So essentially with fastpages you can write your posts in jupyter notebook, then commit to your github repository and the content will automatically be hosted at your domain on github pages. . Caveats . Following official installation worked smoothly for me. While customizing the blog further for my purposes there were several things that did not work right of the box of took some time to find out how to change: . Solved . I wanted to use numbered $ LaTeX$ equations with hyperlinks, which are not easily supported. This comment solved my problem! | You need to edit _pages/about.md to customize the way your &quot;about&quot; page is displayed. | To customize the front page you need to edit index.html. This is literally written on the front page of your blog, but I have not noticed it for a while. | Initially a lot of troubleshooting is needed to get the appearance of the blog I wanted. Commiting and waiting for the online web page to set up is super-slow. Here is an official guide on how to setup a live preview of your blog locally. One minor point that was a problem for me is that the default local server for blog preview https://127.0.0.1:4000 was not correct. After running sudo make server one of the outputs that jekyll produces is Server address: http://0.0.0.0:4000/blog/ which was the correct address for the live preview of my blog. | You need to do some work to make your site appear in google search results. This manual is very helpful, but a bit outdated: some of the things like generating sitemap.xml are now automated and do not require additional work as described in that post. | Not solved . On the web page the display equations of $ LaTeX$ have fluctuations in size which does not look good. |",
            "url": "https://idnm.github.io/blog/blog/fastpages/2021/07/11/How-this-blog-was-set-up.html",
            "relUrl": "/fastpages/2021/07/11/How-this-blog-was-set-up.html",
            "date": " ‚Ä¢ Jul 11, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "My name is Nikita Nemkov, I am a theoretical physicist diving into the field of quantum computation. On this blog I consolidate some of my thoughts on the subject, from reviews of the basic concepts to brief reports on the newest research papers. . I do not expect to have many readers and I do not tailor my posts to any particular audience. Perhaps the reader that could benefit from these notes the most is me, before writing them. Yet, if you found anything that I wrote useful give me a quick feedback in the comments or drop an email! .",
          "url": "https://idnm.github.io/blog/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://idnm.github.io/blog/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}